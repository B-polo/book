<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.1 Clustering: Grouping samples based on their similarity | Computational Genomics with R</title>
  <meta name="description" content="A guide to computationa genomics using R. The book covers fundemental topics with practical examples for an interdisciplinery audience" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="4.1 Clustering: Grouping samples based on their similarity | Computational Genomics with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://compmgenomr.github.io/book/" />
  <meta property="og:image" content="https://compmgenomr.github.io/book/images/cover.jpg" />
  <meta property="og:description" content="A guide to computationa genomics using R. The book covers fundemental topics with practical examples for an interdisciplinery audience" />
  <meta name="github-repo" content="compgenomr/book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.1 Clustering: Grouping samples based on their similarity | Computational Genomics with R" />
  
  <meta name="twitter:description" content="A guide to computationa genomics using R. The book covers fundemental topics with practical examples for an interdisciplinery audience" />
  <meta name="twitter:image" content="https://compmgenomr.github.io/book/images/cover.jpg" />

<meta name="author" content="Altuna Akalin" />


<meta name="date" content="2020-09-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="unsupervisedLearning.html"/>
<link rel="next" href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83786243-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-83786243-1');
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Computational Genomics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="who-is-this-book-for.html"><a href="who-is-this-book-for.html"><i class="fa fa-check"></i>Who is this book for?</a><ul>
<li class="chapter" data-level="" data-path="who-is-this-book-for.html"><a href="who-is-this-book-for.html#what-will-you-get-out-of-this"><i class="fa fa-check"></i>What will you get out of this?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="structure-of-the-book.html"><a href="structure-of-the-book.html"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="software-information-and-conventions.html"><a href="software-information-and-conventions.html"><i class="fa fa-check"></i>Software information and conventions</a><ul>
<li class="chapter" data-level="" data-path="software-information-and-conventions.html"><a href="software-information-and-conventions.html#assignment-operator-convention"><i class="fa fa-check"></i>Assignment operator convention</a></li>
<li class="chapter" data-level="" data-path="software-information-and-conventions.html"><a href="software-information-and-conventions.html#packages-needed-to-run-the-book-code"><i class="fa fa-check"></i>Packages needed to run the book code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-for-the-book.html"><a href="data-for-the-book.html"><i class="fa fa-check"></i>Data for the book</a></li>
<li class="chapter" data-level="" data-path="exercises-in-the-book.html"><a href="exercises-in-the-book.html"><i class="fa fa-check"></i>Exercises in the book</a></li>
<li class="chapter" data-level="" data-path="reproducibility-statement.html"><a href="reproducibility-statement.html"><i class="fa fa-check"></i>Reproducibility statement</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="how-to-contribute.html"><a href="how-to-contribute.html"><i class="fa fa-check"></i>How to contribute</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction to Genomics</a><ul>
<li class="chapter" data-level="1.1" data-path="genes-dna-and-central-dogma.html"><a href="genes-dna-and-central-dogma.html"><i class="fa fa-check"></i><b>1.1</b> Genes, DNA and central dogma</a><ul>
<li class="chapter" data-level="1.1.1" data-path="genes-dna-and-central-dogma.html"><a href="genes-dna-and-central-dogma.html#what-is-a-genome"><i class="fa fa-check"></i><b>1.1.1</b> What is a genome?</a></li>
<li class="chapter" data-level="1.1.2" data-path="genes-dna-and-central-dogma.html"><a href="genes-dna-and-central-dogma.html#what-is-a-gene"><i class="fa fa-check"></i><b>1.1.2</b> What is a gene?</a></li>
<li class="chapter" data-level="1.1.3" data-path="genes-dna-and-central-dogma.html"><a href="genes-dna-and-central-dogma.html#how-are-genes-controlled-transcriptional-and-post-transcriptional-regulation"><i class="fa fa-check"></i><b>1.1.3</b> How are genes controlled? Transcriptional and post-transcriptional regulation</a></li>
<li class="chapter" data-level="1.1.4" data-path="genes-dna-and-central-dogma.html"><a href="genes-dna-and-central-dogma.html#what-does-a-gene-look-like"><i class="fa fa-check"></i><b>1.1.4</b> What does a gene look like?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="elements-of-gene-regulation.html"><a href="elements-of-gene-regulation.html"><i class="fa fa-check"></i><b>1.2</b> Elements of gene regulation</a><ul>
<li class="chapter" data-level="1.2.1" data-path="elements-of-gene-regulation.html"><a href="elements-of-gene-regulation.html#transcriptional-regulation"><i class="fa fa-check"></i><b>1.2.1</b> Transcriptional regulation</a></li>
<li class="chapter" data-level="1.2.2" data-path="elements-of-gene-regulation.html"><a href="elements-of-gene-regulation.html#post-transcriptional-regulation"><i class="fa fa-check"></i><b>1.2.2</b> Post-transcriptional regulation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="shaping-the-genome-dna-mutation.html"><a href="shaping-the-genome-dna-mutation.html"><i class="fa fa-check"></i><b>1.3</b> Shaping the genome: DNA mutation</a></li>
<li class="chapter" data-level="1.4" data-path="high-throughput-experimental-methods-in-genomics.html"><a href="high-throughput-experimental-methods-in-genomics.html"><i class="fa fa-check"></i><b>1.4</b> High-throughput experimental methods in genomics</a><ul>
<li class="chapter" data-level="1.4.1" data-path="high-throughput-experimental-methods-in-genomics.html"><a href="high-throughput-experimental-methods-in-genomics.html#the-general-idea-behind-high-throughput-techniques"><i class="fa fa-check"></i><b>1.4.1</b> The general idea behind high-throughput techniques</a></li>
<li class="chapter" data-level="1.4.2" data-path="high-throughput-experimental-methods-in-genomics.html"><a href="high-throughput-experimental-methods-in-genomics.html#high-throughput-sequencing"><i class="fa fa-check"></i><b>1.4.2</b> High-throughput sequencing</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="visualization-and-data-repositories-for-genomics.html"><a href="visualization-and-data-repositories-for-genomics.html"><i class="fa fa-check"></i><b>1.5</b> Visualization and data repositories for genomics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Rintro.html"><a href="Rintro.html"><i class="fa fa-check"></i><b>2</b> Introduction to R for Genomic Data Analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html"><i class="fa fa-check"></i><b>2.1</b> Steps of (genomic) data analysis</a><ul>
<li class="chapter" data-level="2.1.1" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#data-collection"><i class="fa fa-check"></i><b>2.1.1</b> Data collection</a></li>
<li class="chapter" data-level="2.1.2" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#data-quality-check-and-cleaning"><i class="fa fa-check"></i><b>2.1.2</b> Data quality check and cleaning</a></li>
<li class="chapter" data-level="2.1.3" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#data-processing"><i class="fa fa-check"></i><b>2.1.3</b> Data processing</a></li>
<li class="chapter" data-level="2.1.4" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#exploratory-data-analysis-and-modeling"><i class="fa fa-check"></i><b>2.1.4</b> Exploratory data analysis and modeling</a></li>
<li class="chapter" data-level="2.1.5" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#visualization-and-reporting"><i class="fa fa-check"></i><b>2.1.5</b> Visualization and reporting</a></li>
<li class="chapter" data-level="2.1.6" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#why-use-r-for-genomics"><i class="fa fa-check"></i><b>2.1.6</b> Why use R for genomics ?</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html"><i class="fa fa-check"></i><b>2.2</b> Getting started with R</a><ul>
<li class="chapter" data-level="2.2.1" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#installing-packages"><i class="fa fa-check"></i><b>2.2.1</b> Installing packages</a></li>
<li class="chapter" data-level="2.2.2" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#installing-packages-in-custom-locations"><i class="fa fa-check"></i><b>2.2.2</b> Installing packages in custom locations</a></li>
<li class="chapter" data-level="2.2.3" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#getting-help-on-functions-and-packages"><i class="fa fa-check"></i><b>2.2.3</b> Getting help on functions and packages</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="computations-in-r.html"><a href="computations-in-r.html"><i class="fa fa-check"></i><b>2.3</b> Computations in R</a></li>
<li class="chapter" data-level="2.4" data-path="data-structures.html"><a href="data-structures.html"><i class="fa fa-check"></i><b>2.4</b> Data structures</a><ul>
<li class="chapter" data-level="2.4.1" data-path="data-structures.html"><a href="data-structures.html#vectors"><i class="fa fa-check"></i><b>2.4.1</b> Vectors</a></li>
<li class="chapter" data-level="2.4.2" data-path="data-structures.html"><a href="data-structures.html#matrices"><i class="fa fa-check"></i><b>2.4.2</b> Matrices</a></li>
<li class="chapter" data-level="2.4.3" data-path="data-structures.html"><a href="data-structures.html#data-frames"><i class="fa fa-check"></i><b>2.4.3</b> Data frames</a></li>
<li class="chapter" data-level="2.4.4" data-path="data-structures.html"><a href="data-structures.html#lists"><i class="fa fa-check"></i><b>2.4.4</b> Lists</a></li>
<li class="chapter" data-level="2.4.5" data-path="data-structures.html"><a href="data-structures.html#factors"><i class="fa fa-check"></i><b>2.4.5</b> Factors</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="data-types.html"><a href="data-types.html"><i class="fa fa-check"></i><b>2.5</b> Data types</a></li>
<li class="chapter" data-level="2.6" data-path="reading-and-writing-data.html"><a href="reading-and-writing-data.html"><i class="fa fa-check"></i><b>2.6</b> Reading and writing data</a><ul>
<li class="chapter" data-level="2.6.1" data-path="reading-and-writing-data.html"><a href="reading-and-writing-data.html#reading-large-files"><i class="fa fa-check"></i><b>2.6.1</b> Reading large files</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="plotting-in-r-with-base-graphics.html"><a href="plotting-in-r-with-base-graphics.html"><i class="fa fa-check"></i><b>2.7</b> Plotting in R with base graphics</a><ul>
<li class="chapter" data-level="2.7.1" data-path="plotting-in-r-with-base-graphics.html"><a href="plotting-in-r-with-base-graphics.html#combining-multiple-plots"><i class="fa fa-check"></i><b>2.7.1</b> Combining multiple plots</a></li>
<li class="chapter" data-level="2.7.2" data-path="plotting-in-r-with-base-graphics.html"><a href="plotting-in-r-with-base-graphics.html#saving-plots"><i class="fa fa-check"></i><b>2.7.2</b> Saving plots</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="plotting-in-r-with-ggplot2.html"><a href="plotting-in-r-with-ggplot2.html"><i class="fa fa-check"></i><b>2.8</b> Plotting in R with ggplot2</a><ul>
<li class="chapter" data-level="2.8.1" data-path="plotting-in-r-with-ggplot2.html"><a href="plotting-in-r-with-ggplot2.html#combining-multiple-plots-1"><i class="fa fa-check"></i><b>2.8.1</b> Combining multiple plots</a></li>
<li class="chapter" data-level="2.8.2" data-path="plotting-in-r-with-ggplot2.html"><a href="plotting-in-r-with-ggplot2.html#ggplot2-and-tidyverse"><i class="fa fa-check"></i><b>2.8.2</b> ggplot2 and tidyverse</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="functions-and-control-structures-for-ifelse-etc-.html"><a href="functions-and-control-structures-for-ifelse-etc-.html"><i class="fa fa-check"></i><b>2.9</b> Functions and control structures (for, if/else etc.)</a><ul>
<li class="chapter" data-level="2.9.1" data-path="functions-and-control-structures-for-ifelse-etc-.html"><a href="functions-and-control-structures-for-ifelse-etc-.html#user-defined-functions"><i class="fa fa-check"></i><b>2.9.1</b> User-defined functions</a></li>
<li class="chapter" data-level="2.9.2" data-path="functions-and-control-structures-for-ifelse-etc-.html"><a href="functions-and-control-structures-for-ifelse-etc-.html#loops-and-looping-structures-in-r"><i class="fa fa-check"></i><b>2.9.2</b> Loops and looping structures in R</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.10</b> Exercises</a><ul>
<li class="chapter" data-level="2.10.1" data-path="exercises.html"><a href="exercises.html#computations-in-r-1"><i class="fa fa-check"></i><b>2.10.1</b> Computations in R</a></li>
<li class="chapter" data-level="2.10.2" data-path="exercises.html"><a href="exercises.html#data-structures-in-r"><i class="fa fa-check"></i><b>2.10.2</b> Data structures in R</a></li>
<li class="chapter" data-level="2.10.3" data-path="exercises.html"><a href="exercises.html#reading-in-and-writing-data-out-in-r"><i class="fa fa-check"></i><b>2.10.3</b> Reading in and writing data out in R</a></li>
<li class="chapter" data-level="2.10.4" data-path="exercises.html"><a href="exercises.html#plotting-in-r"><i class="fa fa-check"></i><b>2.10.4</b> Plotting in R</a></li>
<li class="chapter" data-level="2.10.5" data-path="exercises.html"><a href="exercises.html#functions-and-control-structures-for-ifelse-etc.-1"><i class="fa fa-check"></i><b>2.10.5</b> Functions and control structures (for, if/else, etc.)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stats.html"><a href="stats.html"><i class="fa fa-check"></i><b>3</b> Statistics for Genomics</a><ul>
<li class="chapter" data-level="3.1" data-path="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html"><a href="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html"><i class="fa fa-check"></i><b>3.1</b> How to summarize collection of data points: The idea behind statistical distributions</a><ul>
<li class="chapter" data-level="3.1.1" data-path="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html"><a href="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html#describing-the-central-tendency-mean-and-median"><i class="fa fa-check"></i><b>3.1.1</b> Describing the central tendency: Mean and median</a></li>
<li class="chapter" data-level="3.1.2" data-path="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html"><a href="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html#describing-the-spread-measurements-of-variation"><i class="fa fa-check"></i><b>3.1.2</b> Describing the spread: Measurements of variation</a></li>
<li class="chapter" data-level="3.1.3" data-path="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html"><a href="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html#precision-of-estimates-confidence-intervals"><i class="fa fa-check"></i><b>3.1.3</b> Precision of estimates: Confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="how-to-test-for-differences-between-samples.html"><a href="how-to-test-for-differences-between-samples.html"><i class="fa fa-check"></i><b>3.2</b> How to test for differences between samples</a><ul>
<li class="chapter" data-level="3.2.1" data-path="how-to-test-for-differences-between-samples.html"><a href="how-to-test-for-differences-between-samples.html#randomization-based-testing-for-difference-of-the-means"><i class="fa fa-check"></i><b>3.2.1</b> Randomization-based testing for difference of the means</a></li>
<li class="chapter" data-level="3.2.2" data-path="how-to-test-for-differences-between-samples.html"><a href="how-to-test-for-differences-between-samples.html#using-t-test-for-difference-of-the-means-between-two-samples"><i class="fa fa-check"></i><b>3.2.2</b> Using t-test for difference of the means between two samples</a></li>
<li class="chapter" data-level="3.2.3" data-path="how-to-test-for-differences-between-samples.html"><a href="how-to-test-for-differences-between-samples.html#multiple-testing-correction"><i class="fa fa-check"></i><b>3.2.3</b> Multiple testing correction</a></li>
<li class="chapter" data-level="3.2.4" data-path="how-to-test-for-differences-between-samples.html"><a href="how-to-test-for-differences-between-samples.html#moderated-t-tests-using-information-from-multiple-comparisons"><i class="fa fa-check"></i><b>3.2.4</b> Moderated t-tests: Using information from multiple comparisons</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html"><i class="fa fa-check"></i><b>3.3</b> Relationship between variables: Linear models and correlation</a><ul>
<li class="chapter" data-level="3.3.1" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html#how-to-fit-a-line"><i class="fa fa-check"></i><b>3.3.1</b> How to fit a line</a></li>
<li class="chapter" data-level="3.3.2" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html#how-to-estimate-the-error-of-the-coefficients"><i class="fa fa-check"></i><b>3.3.2</b> How to estimate the error of the coefficients</a></li>
<li class="chapter" data-level="3.3.3" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html#accuracy-of-the-model"><i class="fa fa-check"></i><b>3.3.3</b> Accuracy of the model</a></li>
<li class="chapter" data-level="3.3.4" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html#regression-with-categorical-variables"><i class="fa fa-check"></i><b>3.3.4</b> Regression with categorical variables</a></li>
<li class="chapter" data-level="3.3.5" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html#regression-pitfalls"><i class="fa fa-check"></i><b>3.3.5</b> Regression pitfalls</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>3.4</b> Exercises</a><ul>
<li class="chapter" data-level="3.4.1" data-path="exercises-1.html"><a href="exercises-1.html#how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions-1"><i class="fa fa-check"></i><b>3.4.1</b> How to summarize collection of data points: The idea behind statistical distributions</a></li>
<li class="chapter" data-level="3.4.2" data-path="exercises-1.html"><a href="exercises-1.html#how-to-test-for-differences-in-samples"><i class="fa fa-check"></i><b>3.4.2</b> How to test for differences in samples</a></li>
<li class="chapter" data-level="3.4.3" data-path="exercises-1.html"><a href="exercises-1.html#relationship-between-variables-linear-models-and-correlation-1"><i class="fa fa-check"></i><b>3.4.3</b> Relationship between variables: Linear models and correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="unsupervisedLearning.html"><a href="unsupervisedLearning.html"><i class="fa fa-check"></i><b>4</b> Exploratory Data Analysis with Unsupervised Machine Learning</a><ul>
<li class="chapter" data-level="4.1" data-path="clustering-grouping-samples-based-on-their-similarity.html"><a href="clustering-grouping-samples-based-on-their-similarity.html"><i class="fa fa-check"></i><b>4.1</b> Clustering: Grouping samples based on their similarity</a><ul>
<li class="chapter" data-level="4.1.1" data-path="clustering-grouping-samples-based-on-their-similarity.html"><a href="clustering-grouping-samples-based-on-their-similarity.html#distance-metrics"><i class="fa fa-check"></i><b>4.1.1</b> Distance metrics</a></li>
<li class="chapter" data-level="4.1.2" data-path="clustering-grouping-samples-based-on-their-similarity.html"><a href="clustering-grouping-samples-based-on-their-similarity.html#hiearchical-clustering"><i class="fa fa-check"></i><b>4.1.2</b> Hiearchical clustering</a></li>
<li class="chapter" data-level="4.1.3" data-path="clustering-grouping-samples-based-on-their-similarity.html"><a href="clustering-grouping-samples-based-on-their-similarity.html#k-means-clustering"><i class="fa fa-check"></i><b>4.1.3</b> K-means clustering</a></li>
<li class="chapter" data-level="4.1.4" data-path="clustering-grouping-samples-based-on-their-similarity.html"><a href="clustering-grouping-samples-based-on-their-similarity.html#how-to-choose-k-the-number-of-clusters"><i class="fa fa-check"></i><b>4.1.4</b> How to choose “k”, the number of clusters</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><i class="fa fa-check"></i><b>4.2</b> Dimensionality reduction techniques: Visualizing complex data sets in 2D</a><ul>
<li class="chapter" data-level="4.2.1" data-path="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#principal-component-analysis"><i class="fa fa-check"></i><b>4.2.1</b> Principal component analysis</a></li>
<li class="chapter" data-level="4.2.2" data-path="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#other-matrix-factorization-methods-for-dimensionality-reduction"><i class="fa fa-check"></i><b>4.2.2</b> Other matrix factorization methods for dimensionality reduction</a></li>
<li class="chapter" data-level="4.2.3" data-path="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#multi-dimensional-scaling"><i class="fa fa-check"></i><b>4.2.3</b> Multi-dimensional scaling</a></li>
<li class="chapter" data-level="4.2.4" data-path="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#t-distributed-stochastic-neighbor-embedding-t-sne"><i class="fa fa-check"></i><b>4.2.4</b> t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>4.3</b> Exercises</a><ul>
<li class="chapter" data-level="4.3.1" data-path="exercises-2.html"><a href="exercises-2.html#clustering"><i class="fa fa-check"></i><b>4.3.1</b> Clustering</a></li>
<li class="chapter" data-level="4.3.2" data-path="exercises-2.html"><a href="exercises-2.html#dimension-reduction"><i class="fa fa-check"></i><b>4.3.2</b> Dimension reduction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="supervisedLearning.html"><a href="supervisedLearning.html"><i class="fa fa-check"></i><b>5</b> Predictive Modeling with Supervised Machine Learning</a><ul>
<li class="chapter" data-level="5.1" data-path="how-are-machine-learning-models-fit.html"><a href="how-are-machine-learning-models-fit.html"><i class="fa fa-check"></i><b>5.1</b> How are machine learning models fit?</a><ul>
<li class="chapter" data-level="5.1.1" data-path="how-are-machine-learning-models-fit.html"><a href="how-are-machine-learning-models-fit.html#machine-learning-vs.-statistics"><i class="fa fa-check"></i><b>5.1.1</b> Machine learning vs. statistics</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="steps-in-supervised-machine-learning.html"><a href="steps-in-supervised-machine-learning.html"><i class="fa fa-check"></i><b>5.2</b> Steps in supervised machine learning</a></li>
<li class="chapter" data-level="5.3" data-path="use-case-disease-subtype-from-genomics-data.html"><a href="use-case-disease-subtype-from-genomics-data.html"><i class="fa fa-check"></i><b>5.3</b> Use case: Disease subtype from genomics data</a></li>
<li class="chapter" data-level="5.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html"><i class="fa fa-check"></i><b>5.4</b> Data preprocessing</a><ul>
<li class="chapter" data-level="5.4.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#data-transformation"><i class="fa fa-check"></i><b>5.4.1</b> Data transformation</a></li>
<li class="chapter" data-level="5.4.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#filtering-data-and-scaling"><i class="fa fa-check"></i><b>5.4.2</b> Filtering data and scaling</a></li>
<li class="chapter" data-level="5.4.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#dealing-with-missing-values"><i class="fa fa-check"></i><b>5.4.3</b> Dealing with missing values</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="splitting-the-data.html"><a href="splitting-the-data.html"><i class="fa fa-check"></i><b>5.5</b> Splitting the data</a><ul>
<li class="chapter" data-level="5.5.1" data-path="splitting-the-data.html"><a href="splitting-the-data.html#holdout-test-dataset"><i class="fa fa-check"></i><b>5.5.1</b> Holdout test dataset</a></li>
<li class="chapter" data-level="5.5.2" data-path="splitting-the-data.html"><a href="splitting-the-data.html#cross-validation"><i class="fa fa-check"></i><b>5.5.2</b> Cross-validation</a></li>
<li class="chapter" data-level="5.5.3" data-path="splitting-the-data.html"><a href="splitting-the-data.html#bootstrap-resampling"><i class="fa fa-check"></i><b>5.5.3</b> Bootstrap resampling</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="predicting-the-subtype-with-k-nearest-neighbors.html"><a href="predicting-the-subtype-with-k-nearest-neighbors.html"><i class="fa fa-check"></i><b>5.6</b> Predicting the subtype with k-nearest neighbors</a></li>
<li class="chapter" data-level="5.7" data-path="assessing-the-performance-of-our-model.html"><a href="assessing-the-performance-of-our-model.html"><i class="fa fa-check"></i><b>5.7</b> Assessing the performance of our model</a><ul>
<li class="chapter" data-level="5.7.1" data-path="assessing-the-performance-of-our-model.html"><a href="assessing-the-performance-of-our-model.html#receiver-operating-characteristic-roc-curves"><i class="fa fa-check"></i><b>5.7.1</b> Receiver Operating Characteristic (ROC) curves</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="model-tuning-and-avoiding-overfitting.html"><a href="model-tuning-and-avoiding-overfitting.html"><i class="fa fa-check"></i><b>5.8</b> Model tuning and avoiding overfitting</a><ul>
<li class="chapter" data-level="5.8.1" data-path="model-tuning-and-avoiding-overfitting.html"><a href="model-tuning-and-avoiding-overfitting.html#model-complexity-and-bias-variance-trade-off"><i class="fa fa-check"></i><b>5.8.1</b> Model complexity and bias variance trade-off</a></li>
<li class="chapter" data-level="5.8.2" data-path="model-tuning-and-avoiding-overfitting.html"><a href="model-tuning-and-avoiding-overfitting.html#data-split-strategies-for-model-tuning-and-testing"><i class="fa fa-check"></i><b>5.8.2</b> Data split strategies for model tuning and testing</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="variable-importance.html"><a href="variable-importance.html"><i class="fa fa-check"></i><b>5.9</b> Variable importance</a></li>
<li class="chapter" data-level="5.10" data-path="how-to-deal-with-class-imbalance.html"><a href="how-to-deal-with-class-imbalance.html"><i class="fa fa-check"></i><b>5.10</b> How to deal with class imbalance</a><ul>
<li class="chapter" data-level="5.10.1" data-path="how-to-deal-with-class-imbalance.html"><a href="how-to-deal-with-class-imbalance.html#sampling-for-class-balance"><i class="fa fa-check"></i><b>5.10.1</b> Sampling for class balance</a></li>
<li class="chapter" data-level="5.10.2" data-path="how-to-deal-with-class-imbalance.html"><a href="how-to-deal-with-class-imbalance.html#altering-case-weights"><i class="fa fa-check"></i><b>5.10.2</b> Altering case weights</a></li>
<li class="chapter" data-level="5.10.3" data-path="how-to-deal-with-class-imbalance.html"><a href="how-to-deal-with-class-imbalance.html#selecting-different-classification-score-cutoffs"><i class="fa fa-check"></i><b>5.10.3</b> Selecting different classification score cutoffs</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="dealing-with-correlated-predictors.html"><a href="dealing-with-correlated-predictors.html"><i class="fa fa-check"></i><b>5.11</b> Dealing with correlated predictors</a></li>
<li class="chapter" data-level="5.12" data-path="trees-and-forests-random-forests-in-action.html"><a href="trees-and-forests-random-forests-in-action.html"><i class="fa fa-check"></i><b>5.12</b> Trees and forests: Random forests in action</a><ul>
<li class="chapter" data-level="5.12.1" data-path="trees-and-forests-random-forests-in-action.html"><a href="trees-and-forests-random-forests-in-action.html#decision-trees"><i class="fa fa-check"></i><b>5.12.1</b> Decision trees</a></li>
<li class="chapter" data-level="5.12.2" data-path="trees-and-forests-random-forests-in-action.html"><a href="trees-and-forests-random-forests-in-action.html#trees-to-forests"><i class="fa fa-check"></i><b>5.12.2</b> Trees to forests</a></li>
<li class="chapter" data-level="5.12.3" data-path="trees-and-forests-random-forests-in-action.html"><a href="trees-and-forests-random-forests-in-action.html#variable-importance-1"><i class="fa fa-check"></i><b>5.12.3</b> Variable importance</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="logistic-regression-and-regularization.html"><a href="logistic-regression-and-regularization.html"><i class="fa fa-check"></i><b>5.13</b> Logistic regression and regularization</a><ul>
<li class="chapter" data-level="5.13.1" data-path="logistic-regression-and-regularization.html"><a href="logistic-regression-and-regularization.html#regularization-in-order-to-avoid-overfitting"><i class="fa fa-check"></i><b>5.13.1</b> Regularization in order to avoid overfitting</a></li>
<li class="chapter" data-level="5.13.2" data-path="logistic-regression-and-regularization.html"><a href="logistic-regression-and-regularization.html#variable-importance-2"><i class="fa fa-check"></i><b>5.13.2</b> Variable importance</a></li>
</ul></li>
<li class="chapter" data-level="5.14" data-path="other-supervised-algorithms.html"><a href="other-supervised-algorithms.html"><i class="fa fa-check"></i><b>5.14</b> Other supervised algorithms</a><ul>
<li class="chapter" data-level="5.14.1" data-path="other-supervised-algorithms.html"><a href="other-supervised-algorithms.html#gradient-boosting"><i class="fa fa-check"></i><b>5.14.1</b> Gradient boosting</a></li>
<li class="chapter" data-level="5.14.2" data-path="other-supervised-algorithms.html"><a href="other-supervised-algorithms.html#support-vector-machines-svm"><i class="fa fa-check"></i><b>5.14.2</b> Support Vector Machines (SVM)</a></li>
<li class="chapter" data-level="5.14.3" data-path="other-supervised-algorithms.html"><a href="other-supervised-algorithms.html#neural-networks-and-deep-versions-of-it"><i class="fa fa-check"></i><b>5.14.3</b> Neural networks and deep versions of it</a></li>
<li class="chapter" data-level="5.14.4" data-path="other-supervised-algorithms.html"><a href="other-supervised-algorithms.html#ensemble-learning"><i class="fa fa-check"></i><b>5.14.4</b> Ensemble learning</a></li>
</ul></li>
<li class="chapter" data-level="5.15" data-path="predicting-continuous-variables-regression-with-machine-learning.html"><a href="predicting-continuous-variables-regression-with-machine-learning.html"><i class="fa fa-check"></i><b>5.15</b> Predicting continuous variables: Regression with machine learning</a><ul>
<li class="chapter" data-level="5.15.1" data-path="predicting-continuous-variables-regression-with-machine-learning.html"><a href="predicting-continuous-variables-regression-with-machine-learning.html#use-case-predicting-age-from-dna-methylation"><i class="fa fa-check"></i><b>5.15.1</b> Use case: Predicting age from DNA methylation</a></li>
<li class="chapter" data-level="5.15.2" data-path="predicting-continuous-variables-regression-with-machine-learning.html"><a href="predicting-continuous-variables-regression-with-machine-learning.html#reading-and-processing-the-data"><i class="fa fa-check"></i><b>5.15.2</b> Reading and processing the data</a></li>
<li class="chapter" data-level="5.15.3" data-path="predicting-continuous-variables-regression-with-machine-learning.html"><a href="predicting-continuous-variables-regression-with-machine-learning.html#running-random-forest-regression"><i class="fa fa-check"></i><b>5.15.3</b> Running random forest regression</a></li>
</ul></li>
<li class="chapter" data-level="5.16" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>5.16</b> Exercises</a><ul>
<li class="chapter" data-level="5.16.1" data-path="exercises-3.html"><a href="exercises-3.html#classification"><i class="fa fa-check"></i><b>5.16.1</b> Classification</a></li>
<li class="chapter" data-level="5.16.2" data-path="exercises-3.html"><a href="exercises-3.html#regression"><i class="fa fa-check"></i><b>5.16.2</b> Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="genomicIntervals.html"><a href="genomicIntervals.html"><i class="fa fa-check"></i><b>6</b> Operations on Genomic Intervals and Genome Arithmetic</a><ul>
<li class="chapter" data-level="6.1" data-path="operations-on-genomic-intervals-with-genomicranges-package.html"><a href="operations-on-genomic-intervals-with-genomicranges-package.html"><i class="fa fa-check"></i><b>6.1</b> Operations on genomic intervals with <code>GenomicRanges</code> package</a><ul>
<li class="chapter" data-level="6.1.1" data-path="operations-on-genomic-intervals-with-genomicranges-package.html"><a href="operations-on-genomic-intervals-with-genomicranges-package.html#how-to-create-and-manipulate-a-granges-object"><i class="fa fa-check"></i><b>6.1.1</b> How to create and manipulate a GRanges object</a></li>
<li class="chapter" data-level="6.1.2" data-path="operations-on-genomic-intervals-with-genomicranges-package.html"><a href="operations-on-genomic-intervals-with-genomicranges-package.html#getting-genomic-regions-into-r-as-granges-objects"><i class="fa fa-check"></i><b>6.1.2</b> Getting genomic regions into R as GRanges objects</a></li>
<li class="chapter" data-level="6.1.3" data-path="operations-on-genomic-intervals-with-genomicranges-package.html"><a href="operations-on-genomic-intervals-with-genomicranges-package.html#finding-regions-that-dodo-not-overlap-with-another-set-of-regions"><i class="fa fa-check"></i><b>6.1.3</b> Finding regions that do/do not overlap with another set of regions</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="dealing-with-mapped-high-throughput-sequencing-reads.html"><a href="dealing-with-mapped-high-throughput-sequencing-reads.html"><i class="fa fa-check"></i><b>6.2</b> Dealing with mapped high-throughput sequencing reads</a><ul>
<li class="chapter" data-level="6.2.1" data-path="dealing-with-mapped-high-throughput-sequencing-reads.html"><a href="dealing-with-mapped-high-throughput-sequencing-reads.html#counting-mapped-reads-for-a-set-of-regions"><i class="fa fa-check"></i><b>6.2.1</b> Counting mapped reads for a set of regions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="dealing-with-continuous-scores-over-the-genome.html"><a href="dealing-with-continuous-scores-over-the-genome.html"><i class="fa fa-check"></i><b>6.3</b> Dealing with continuous scores over the genome</a><ul>
<li class="chapter" data-level="6.3.1" data-path="dealing-with-continuous-scores-over-the-genome.html"><a href="dealing-with-continuous-scores-over-the-genome.html#extracting-subsections-of-rle-and-rlelist-objects"><i class="fa fa-check"></i><b>6.3.1</b> Extracting subsections of Rle and RleList objects</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="genomic-intervals-with-more-information-summarizedexperiment-class.html"><a href="genomic-intervals-with-more-information-summarizedexperiment-class.html"><i class="fa fa-check"></i><b>6.4</b> Genomic intervals with more information: SummarizedExperiment class</a><ul>
<li class="chapter" data-level="6.4.1" data-path="genomic-intervals-with-more-information-summarizedexperiment-class.html"><a href="genomic-intervals-with-more-information-summarizedexperiment-class.html#create-a-summarizedexperiment-object"><i class="fa fa-check"></i><b>6.4.1</b> Create a SummarizedExperiment object</a></li>
<li class="chapter" data-level="6.4.2" data-path="genomic-intervals-with-more-information-summarizedexperiment-class.html"><a href="genomic-intervals-with-more-information-summarizedexperiment-class.html#subset-and-manipulate-the-summarizedexperiment-object"><i class="fa fa-check"></i><b>6.4.2</b> Subset and manipulate the SummarizedExperiment object</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="visualizing-and-summarizing-genomic-intervals.html"><a href="visualizing-and-summarizing-genomic-intervals.html"><i class="fa fa-check"></i><b>6.5</b> Visualizing and summarizing genomic intervals</a><ul>
<li class="chapter" data-level="6.5.1" data-path="visualizing-and-summarizing-genomic-intervals.html"><a href="visualizing-and-summarizing-genomic-intervals.html#visualizing-intervals-on-a-locus-of-interest"><i class="fa fa-check"></i><b>6.5.1</b> Visualizing intervals on a locus of interest</a></li>
<li class="chapter" data-level="6.5.2" data-path="visualizing-and-summarizing-genomic-intervals.html"><a href="visualizing-and-summarizing-genomic-intervals.html#summaries-of-genomic-intervals-on-multiple-loci"><i class="fa fa-check"></i><b>6.5.2</b> Summaries of genomic intervals on multiple loci</a></li>
<li class="chapter" data-level="6.5.3" data-path="visualizing-and-summarizing-genomic-intervals.html"><a href="visualizing-and-summarizing-genomic-intervals.html#making-karyograms-and-circos-plots"><i class="fa fa-check"></i><b>6.5.3</b> Making karyograms and circos plots</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>6.6</b> Exercises</a><ul>
<li class="chapter" data-level="6.6.1" data-path="exercises-4.html"><a href="exercises-4.html#operations-on-genomic-intervals-with-the-genomicranges-package"><i class="fa fa-check"></i><b>6.6.1</b> Operations on genomic intervals with the <code>GenomicRanges</code> package</a></li>
<li class="chapter" data-level="6.6.2" data-path="exercises-4.html"><a href="exercises-4.html#dealing-with-mapped-high-throughput-sequencing-reads-1"><i class="fa fa-check"></i><b>6.6.2</b> Dealing with mapped high-throughput sequencing reads</a></li>
<li class="chapter" data-level="6.6.3" data-path="exercises-4.html"><a href="exercises-4.html#dealing-with-contiguous-scores-over-the-genome"><i class="fa fa-check"></i><b>6.6.3</b> Dealing with contiguous scores over the genome</a></li>
<li class="chapter" data-level="6.6.4" data-path="exercises-4.html"><a href="exercises-4.html#visualizing-and-summarizing-genomic-intervals-1"><i class="fa fa-check"></i><b>6.6.4</b> Visualizing and summarizing genomic intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="processingReads.html"><a href="processingReads.html"><i class="fa fa-check"></i><b>7</b> Quality Check, Processing and Alignment of High-throughput Sequencing Reads</a><ul>
<li class="chapter" data-level="7.1" data-path="fasta-and-fastq-formats.html"><a href="fasta-and-fastq-formats.html"><i class="fa fa-check"></i><b>7.1</b> FASTA and FASTQ formats</a></li>
<li class="chapter" data-level="7.2" data-path="quality-check-on-sequencing-reads.html"><a href="quality-check-on-sequencing-reads.html"><i class="fa fa-check"></i><b>7.2</b> Quality check on sequencing reads</a><ul>
<li class="chapter" data-level="7.2.1" data-path="quality-check-on-sequencing-reads.html"><a href="quality-check-on-sequencing-reads.html#sequence-quality-per-basecycle"><i class="fa fa-check"></i><b>7.2.1</b> Sequence quality per base/cycle</a></li>
<li class="chapter" data-level="7.2.2" data-path="quality-check-on-sequencing-reads.html"><a href="quality-check-on-sequencing-reads.html#sequence-content-per-basecycle"><i class="fa fa-check"></i><b>7.2.2</b> Sequence content per base/cycle</a></li>
<li class="chapter" data-level="7.2.3" data-path="quality-check-on-sequencing-reads.html"><a href="quality-check-on-sequencing-reads.html#read-frequency-plot"><i class="fa fa-check"></i><b>7.2.3</b> Read frequency plot</a></li>
<li class="chapter" data-level="7.2.4" data-path="quality-check-on-sequencing-reads.html"><a href="quality-check-on-sequencing-reads.html#other-quality-metrics-and-qc-tools"><i class="fa fa-check"></i><b>7.2.4</b> Other quality metrics and QC tools</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="filtering-and-trimming-reads.html"><a href="filtering-and-trimming-reads.html"><i class="fa fa-check"></i><b>7.3</b> Filtering and trimming reads</a></li>
<li class="chapter" data-level="7.4" data-path="mappingaligning-reads-to-the-genome.html"><a href="mappingaligning-reads-to-the-genome.html"><i class="fa fa-check"></i><b>7.4</b> Mapping/aligning reads to the genome</a></li>
<li class="chapter" data-level="7.5" data-path="further-processing-of-aligned-reads.html"><a href="further-processing-of-aligned-reads.html"><i class="fa fa-check"></i><b>7.5</b> Further processing of aligned reads</a></li>
<li class="chapter" data-level="7.6" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="rnaseqanalysis.html"><a href="rnaseqanalysis.html"><i class="fa fa-check"></i><b>8</b> RNA-seq Analysis</a><ul>
<li class="chapter" data-level="8.1" data-path="what-is-gene-expression.html"><a href="what-is-gene-expression.html"><i class="fa fa-check"></i><b>8.1</b> What is gene expression?</a></li>
<li class="chapter" data-level="8.2" data-path="methods-to-detect-gene-expression.html"><a href="methods-to-detect-gene-expression.html"><i class="fa fa-check"></i><b>8.2</b> Methods to detect gene expression</a></li>
<li class="chapter" data-level="8.3" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><i class="fa fa-check"></i><b>8.3</b> Gene expression analysis using high-throughput sequencing technologies</a><ul>
<li class="chapter" data-level="8.3.1" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#processing-raw-data"><i class="fa fa-check"></i><b>8.3.1</b> Processing raw data</a></li>
<li class="chapter" data-level="8.3.2" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#alignment"><i class="fa fa-check"></i><b>8.3.2</b> Alignment</a></li>
<li class="chapter" data-level="8.3.3" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#quantification"><i class="fa fa-check"></i><b>8.3.3</b> Quantification</a></li>
<li class="chapter" data-level="8.3.4" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#within-sample-normalization-of-the-read-counts"><i class="fa fa-check"></i><b>8.3.4</b> Within sample normalization of the read counts</a></li>
<li class="chapter" data-level="8.3.5" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#computing-different-normalization-schemes-in-r"><i class="fa fa-check"></i><b>8.3.5</b> Computing different normalization schemes in R</a></li>
<li class="chapter" data-level="8.3.6" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#exploratory-analysis-of-the-read-count-table"><i class="fa fa-check"></i><b>8.3.6</b> Exploratory analysis of the read count table</a></li>
<li class="chapter" data-level="8.3.7" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#differential-expression-analysis"><i class="fa fa-check"></i><b>8.3.7</b> Differential expression analysis</a></li>
<li class="chapter" data-level="8.3.8" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#functional-enrichment-analysis"><i class="fa fa-check"></i><b>8.3.8</b> Functional enrichment analysis</a></li>
<li class="chapter" data-level="8.3.9" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#accounting-for-additional-sources-of-variation"><i class="fa fa-check"></i><b>8.3.9</b> Accounting for additional sources of variation</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="other-applications-of-rna-seq.html"><a href="other-applications-of-rna-seq.html"><i class="fa fa-check"></i><b>8.4</b> Other applications of RNA-seq</a></li>
<li class="chapter" data-level="8.5" data-path="exercises-6.html"><a href="exercises-6.html"><i class="fa fa-check"></i><b>8.5</b> Exercises</a><ul>
<li class="chapter" data-level="8.5.1" data-path="exercises-6.html"><a href="exercises-6.html#exploring-the-count-tables"><i class="fa fa-check"></i><b>8.5.1</b> Exploring the count tables</a></li>
<li class="chapter" data-level="8.5.2" data-path="exercises-6.html"><a href="exercises-6.html#differential-expression-analysis-1"><i class="fa fa-check"></i><b>8.5.2</b> Differential expression analysis</a></li>
<li class="chapter" data-level="8.5.3" data-path="exercises-6.html"><a href="exercises-6.html#functional-enrichment-analysis-1"><i class="fa fa-check"></i><b>8.5.3</b> Functional enrichment analysis</a></li>
<li class="chapter" data-level="8.5.4" data-path="exercises-6.html"><a href="exercises-6.html#removing-unwanted-variation-from-the-expression-data"><i class="fa fa-check"></i><b>8.5.4</b> Removing unwanted variation from the expression data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chipseq.html"><a href="chipseq.html"><i class="fa fa-check"></i><b>9</b> ChIP-seq analysis</a><ul>
<li class="chapter" data-level="9.1" data-path="regulatory-protein-dna-interactions.html"><a href="regulatory-protein-dna-interactions.html"><i class="fa fa-check"></i><b>9.1</b> Regulatory protein-DNA interactions</a></li>
<li class="chapter" data-level="9.2" data-path="measuring-protein-dna-interactions-with-chip-seq.html"><a href="measuring-protein-dna-interactions-with-chip-seq.html"><i class="fa fa-check"></i><b>9.2</b> Measuring protein-DNA interactions with ChIP-seq</a></li>
<li class="chapter" data-level="9.3" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><i class="fa fa-check"></i><b>9.3</b> Factors that affect ChIP-seq experiment and analysis quality</a><ul>
<li class="chapter" data-level="9.3.1" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#antibody-specificity"><i class="fa fa-check"></i><b>9.3.1</b> Antibody specificity</a></li>
<li class="chapter" data-level="9.3.2" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#sequencing-depth"><i class="fa fa-check"></i><b>9.3.2</b> Sequencing depth</a></li>
<li class="chapter" data-level="9.3.3" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#pcr-duplication"><i class="fa fa-check"></i><b>9.3.3</b> PCR duplication</a></li>
<li class="chapter" data-level="9.3.4" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#biological-replicates"><i class="fa fa-check"></i><b>9.3.4</b> Biological replicates</a></li>
<li class="chapter" data-level="9.3.5" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#control-experiments"><i class="fa fa-check"></i><b>9.3.5</b> Control experiments</a></li>
<li class="chapter" data-level="9.3.6" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#using-tagged-proteins"><i class="fa fa-check"></i><b>9.3.6</b> Using tagged proteins</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="pre-processing-chip-data.html"><a href="pre-processing-chip-data.html"><i class="fa fa-check"></i><b>9.4</b> Pre-processing ChIP data</a><ul>
<li class="chapter" data-level="9.4.1" data-path="pre-processing-chip-data.html"><a href="pre-processing-chip-data.html#mapping-of-chip-seq-data"><i class="fa fa-check"></i><b>9.4.1</b> Mapping of ChIP-seq data</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="chip-quality-control.html"><a href="chip-quality-control.html"><i class="fa fa-check"></i><b>9.5</b> ChIP quality control</a><ul>
<li class="chapter" data-level="9.5.1" data-path="chip-quality-control.html"><a href="chip-quality-control.html#the-data"><i class="fa fa-check"></i><b>9.5.1</b> The data</a></li>
<li class="chapter" data-level="9.5.2" data-path="chip-quality-control.html"><a href="chip-quality-control.html#sample-clustering"><i class="fa fa-check"></i><b>9.5.2</b> Sample clustering</a></li>
<li class="chapter" data-level="9.5.3" data-path="chip-quality-control.html"><a href="chip-quality-control.html#visualization-in-the-genome-browser"><i class="fa fa-check"></i><b>9.5.3</b> Visualization in the genome browser</a></li>
<li class="chapter" data-level="9.5.4" data-path="chip-quality-control.html"><a href="chip-quality-control.html#plus-and-minus-strand-cross-correlation"><i class="fa fa-check"></i><b>9.5.4</b> Plus and minus strand cross-correlation</a></li>
<li class="chapter" data-level="9.5.5" data-path="chip-quality-control.html"><a href="chip-quality-control.html#gc-bias-quantification"><i class="fa fa-check"></i><b>9.5.5</b> GC bias quantification</a></li>
<li class="chapter" data-level="9.5.6" data-path="chip-quality-control.html"><a href="chip-quality-control.html#sequence-read-genomic-distribution"><i class="fa fa-check"></i><b>9.5.6</b> Sequence read genomic distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="peak-calling.html"><a href="peak-calling.html"><i class="fa fa-check"></i><b>9.6</b> Peak calling</a><ul>
<li class="chapter" data-level="9.6.1" data-path="peak-calling.html"><a href="peak-calling.html#types-of-chip-seq-experiments"><i class="fa fa-check"></i><b>9.6.1</b> Types of ChIP-seq experiments</a></li>
<li class="chapter" data-level="9.6.2" data-path="peak-calling.html"><a href="peak-calling.html#peak-calling-sharp-peaks"><i class="fa fa-check"></i><b>9.6.2</b> Peak calling: Sharp peaks</a></li>
<li class="chapter" data-level="9.6.3" data-path="peak-calling.html"><a href="peak-calling.html#peak-calling-broad-regions"><i class="fa fa-check"></i><b>9.6.3</b> Peak calling: Broad regions</a></li>
<li class="chapter" data-level="9.6.4" data-path="peak-calling.html"><a href="peak-calling.html#peak-quality-control"><i class="fa fa-check"></i><b>9.6.4</b> Peak quality control</a></li>
<li class="chapter" data-level="9.6.5" data-path="peak-calling.html"><a href="peak-calling.html#peak-annotation"><i class="fa fa-check"></i><b>9.6.5</b> Peak annotation</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="motif-discovery.html"><a href="motif-discovery.html"><i class="fa fa-check"></i><b>9.7</b> Motif discovery</a><ul>
<li class="chapter" data-level="9.7.1" data-path="motif-discovery.html"><a href="motif-discovery.html#motif-comparison"><i class="fa fa-check"></i><b>9.7.1</b> Motif comparison</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="what-to-do-next.html"><a href="what-to-do-next.html"><i class="fa fa-check"></i><b>9.8</b> What to do next?</a></li>
<li class="chapter" data-level="9.9" data-path="exercises-7.html"><a href="exercises-7.html"><i class="fa fa-check"></i><b>9.9</b> Exercises</a><ul>
<li class="chapter" data-level="9.9.1" data-path="exercises-7.html"><a href="exercises-7.html#quality-control"><i class="fa fa-check"></i><b>9.9.1</b> Quality control</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bsseq.html"><a href="bsseq.html"><i class="fa fa-check"></i><b>10</b> DNA methylation analysis using bisulfite sequencing data</a><ul>
<li class="chapter" data-level="10.1" data-path="what-is-dna-methylation.html"><a href="what-is-dna-methylation.html"><i class="fa fa-check"></i><b>10.1</b> What is DNA methylation?</a><ul>
<li class="chapter" data-level="10.1.1" data-path="what-is-dna-methylation.html"><a href="what-is-dna-methylation.html#how-dna-methylation-is-set"><i class="fa fa-check"></i><b>10.1.1</b> How DNA methylation is set ?</a></li>
<li class="chapter" data-level="10.1.2" data-path="what-is-dna-methylation.html"><a href="what-is-dna-methylation.html#how-to-measure-dna-methylation-with-bisulfite-sequencing"><i class="fa fa-check"></i><b>10.1.2</b> How to measure DNA methylation with bisulfite sequencing</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="analyzing-dna-methylation-data.html"><a href="analyzing-dna-methylation-data.html"><i class="fa fa-check"></i><b>10.2</b> Analyzing DNA methylation data</a></li>
<li class="chapter" data-level="10.3" data-path="processing-raw-data-and-getting-data-into-r.html"><a href="processing-raw-data-and-getting-data-into-r.html"><i class="fa fa-check"></i><b>10.3</b> Processing raw data and getting data into R</a></li>
<li class="chapter" data-level="10.4" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html"><i class="fa fa-check"></i><b>10.4</b> Data filtering and exploratory analysis</a><ul>
<li class="chapter" data-level="10.4.1" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#reading-methylation-call-files"><i class="fa fa-check"></i><b>10.4.1</b> Reading methylation call files</a></li>
<li class="chapter" data-level="10.4.2" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#further-quality-check"><i class="fa fa-check"></i><b>10.4.2</b> Further quality check</a></li>
<li class="chapter" data-level="10.4.3" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#merging-samples-into-a-single-table"><i class="fa fa-check"></i><b>10.4.3</b> Merging samples into a single table</a></li>
<li class="chapter" data-level="10.4.4" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#filtering-cpgs"><i class="fa fa-check"></i><b>10.4.4</b> Filtering CpGs</a></li>
<li class="chapter" data-level="10.4.5" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#clustering-samples"><i class="fa fa-check"></i><b>10.4.5</b> Clustering samples</a></li>
<li class="chapter" data-level="10.4.6" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#principal-component-analysis-1"><i class="fa fa-check"></i><b>10.4.6</b> Principal component analysis</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="extracting-interesting-regions-differential-methylation-and-segmentation.html"><a href="extracting-interesting-regions-differential-methylation-and-segmentation.html"><i class="fa fa-check"></i><b>10.5</b> Extracting interesting regions: Differential methylation and segmentation</a><ul>
<li class="chapter" data-level="10.5.1" data-path="extracting-interesting-regions-differential-methylation-and-segmentation.html"><a href="extracting-interesting-regions-differential-methylation-and-segmentation.html#differential-methylation"><i class="fa fa-check"></i><b>10.5.1</b> Differential methylation</a></li>
<li class="chapter" data-level="10.5.2" data-path="extracting-interesting-regions-differential-methylation-and-segmentation.html"><a href="extracting-interesting-regions-differential-methylation-and-segmentation.html#methylation-segmentation"><i class="fa fa-check"></i><b>10.5.2</b> Methylation segmentation</a></li>
<li class="chapter" data-level="10.5.3" data-path="extracting-interesting-regions-differential-methylation-and-segmentation.html"><a href="extracting-interesting-regions-differential-methylation-and-segmentation.html#working-with-large-files"><i class="fa fa-check"></i><b>10.5.3</b> Working with large files</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="annotation-of-dmrsdmcs-and-segments.html"><a href="annotation-of-dmrsdmcs-and-segments.html"><i class="fa fa-check"></i><b>10.6</b> Annotation of DMRs/DMCs and segments</a><ul>
<li class="chapter" data-level="10.6.1" data-path="annotation-of-dmrsdmcs-and-segments.html"><a href="annotation-of-dmrsdmcs-and-segments.html#further-annotation-with-genes-or-gene-sets"><i class="fa fa-check"></i><b>10.6.1</b> Further annotation with genes or gene sets</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="other-r-packages-that-can-be-used-for-methylation-analysis.html"><a href="other-r-packages-that-can-be-used-for-methylation-analysis.html"><i class="fa fa-check"></i><b>10.7</b> Other R packages that can be used for methylation analysis</a></li>
<li class="chapter" data-level="10.8" data-path="exercises-8.html"><a href="exercises-8.html"><i class="fa fa-check"></i><b>10.8</b> Exercises</a><ul>
<li class="chapter" data-level="10.8.1" data-path="exercises-8.html"><a href="exercises-8.html#differential-methylation-1"><i class="fa fa-check"></i><b>10.8.1</b> Differential methylation</a></li>
<li class="chapter" data-level="10.8.2" data-path="exercises-8.html"><a href="exercises-8.html#methylome-segmentation"><i class="fa fa-check"></i><b>10.8.2</b> Methylome segmentation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="multiomics.html"><a href="multiomics.html"><i class="fa fa-check"></i><b>11</b> Multi-omics Analysis</a><ul>
<li class="chapter" data-level="11.1" data-path="use-case-multi-omics-data-from-colorectal-cancer.html"><a href="use-case-multi-omics-data-from-colorectal-cancer.html"><i class="fa fa-check"></i><b>11.1</b> Use case: Multi-omics data from colorectal cancer</a></li>
<li class="chapter" data-level="11.2" data-path="latent-variable-models-for-multi-omics-integration.html"><a href="latent-variable-models-for-multi-omics-integration.html"><i class="fa fa-check"></i><b>11.2</b> Latent variable models for multi-omics integration</a></li>
<li class="chapter" data-level="11.3" data-path="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html"><a href="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html"><i class="fa fa-check"></i><b>11.3</b> Matrix factorization methods for unsupervised multi-omics data integration</a><ul>
<li class="chapter" data-level="11.3.1" data-path="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html"><a href="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html#multiple-factor-analysis"><i class="fa fa-check"></i><b>11.3.1</b> Multiple factor analysis</a></li>
<li class="chapter" data-level="11.3.2" data-path="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html"><a href="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html#joint-non-negative-matrix-factorization"><i class="fa fa-check"></i><b>11.3.2</b> Joint non-negative matrix factorization</a></li>
<li class="chapter" data-level="11.3.3" data-path="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html"><a href="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html#icluster"><i class="fa fa-check"></i><b>11.3.3</b> iCluster</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="clustering-using-latent-factors.html"><a href="clustering-using-latent-factors.html"><i class="fa fa-check"></i><b>11.4</b> Clustering using latent factors</a><ul>
<li class="chapter" data-level="11.4.1" data-path="clustering-using-latent-factors.html"><a href="clustering-using-latent-factors.html#one-hot-clustering"><i class="fa fa-check"></i><b>11.4.1</b> One-hot clustering</a></li>
<li class="chapter" data-level="11.4.2" data-path="clustering-using-latent-factors.html"><a href="clustering-using-latent-factors.html#k-means-clustering-1"><i class="fa fa-check"></i><b>11.4.2</b> K-means clustering</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="biological-interpretation-of-latent-factors.html"><a href="biological-interpretation-of-latent-factors.html"><i class="fa fa-check"></i><b>11.5</b> Biological interpretation of latent factors</a><ul>
<li class="chapter" data-level="11.5.1" data-path="biological-interpretation-of-latent-factors.html"><a href="biological-interpretation-of-latent-factors.html#inspection-of-feature-weights-in-loading-vectors"><i class="fa fa-check"></i><b>11.5.1</b> Inspection of feature weights in loading vectors</a></li>
<li class="chapter" data-level="11.5.2" data-path="biological-interpretation-of-latent-factors.html"><a href="biological-interpretation-of-latent-factors.html#making-sense-of-factors-using-enrichment-analysis"><i class="fa fa-check"></i><b>11.5.2</b> Making sense of factors using enrichment analysis</a></li>
<li class="chapter" data-level="11.5.3" data-path="biological-interpretation-of-latent-factors.html"><a href="biological-interpretation-of-latent-factors.html#interpretation-using-additional-covariates"><i class="fa fa-check"></i><b>11.5.3</b> Interpretation using additional covariates</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="exercises-9.html"><a href="exercises-9.html"><i class="fa fa-check"></i><b>11.6</b> Exercises</a><ul>
<li class="chapter" data-level="11.6.1" data-path="exercises-9.html"><a href="exercises-9.html#matrix-factorization-methods"><i class="fa fa-check"></i><b>11.6.1</b> Matrix factorization methods</a></li>
<li class="chapter" data-level="11.6.2" data-path="exercises-9.html"><a href="exercises-9.html#clustering-using-latent-factors-1"><i class="fa fa-check"></i><b>11.6.2</b> Clustering using latent factors</a></li>
<li class="chapter" data-level="11.6.3" data-path="exercises-9.html"><a href="exercises-9.html#biological-interpretation-of-latent-factors-1"><i class="fa fa-check"></i><b>11.6.3</b> Biological interpretation of latent factors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Genomics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="clustering-grouping-samples-based-on-their-similarity" class="section level2">
<h2><span class="header-section-number">4.1</span> Clustering: Grouping samples based on their similarity</h2>
<p>In genomics, we would very frequently want to assess how our samples relate to each other. Are our replicates similar to each other? Do the samples from the same treatment group have similar genome-wide signals? Do the patients with similar diseases have similar gene expression profiles?
Take the last question for example. We need to define a distance or similarity metric between patients’ expression profiles and use that metric to find groups of patients that are more similar to each other than the rest of the patients. This, in essence, is the general idea behind clustering. We need a distance metric and a method to utilize that distance metric to find self-similar groups. Clustering is a ubiquitous procedure in bioinformatics as well as any field that deals with high-dimensional data. It is very likely that every genomics paper containing multiple samples has some sort of clustering. Due to this ubiquity and general usefulness, it is an essential technique to learn.</p>
<div id="distance-metrics" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Distance metrics</h3>
<p>The first required step for clustering is the distance metric. This is simply a measurement of how similar gene expressions are to each other. There are many options for distance metrics and the choice of the metric is quite important for clustering. Consider a simple example where we have four patients and expression of three genes measured in Table <a href="clustering-grouping-samples-based-on-their-similarity.html#tab:expTable">4.1</a>. Which patients look similar to each other based on their gene expression profiles ?</p>
<table>
<caption><span id="tab:expTable">TABLE 4.1: </span>Gene expressions from patients</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">IRX4</th>
<th align="right">OCT4</th>
<th align="right">PAX6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>patient1</td>
<td align="right">11</td>
<td align="right">10</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td>patient2</td>
<td align="right">13</td>
<td align="right">13</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td>patient3</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td>patient4</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">9</td>
</tr>
</tbody>
</table>
<p>It may not be obvious from the table at first sight, but if we plot the gene expression profile for each patient (shown in Figure <a href="clustering-grouping-samples-based-on-their-similarity.html#fig:expPlot">4.1</a>), we will see that expression profiles of patient 1 and patient 2 are more similar to each other than patient 3 or patient 4.</p>
<div class="figure" style="text-align: center"><span id="fig:expPlot"></span>
<img src="04-unsupervisedLearning_files/figure-html/expPlot-1.png" alt="Gene expression values for different patients. Certain patients have gene expression values that are similar to each other." width="50%" />
<p class="caption">
FIGURE 4.1: Gene expression values for different patients. Certain patients have gene expression values that are similar to each other.
</p>
</div>
<p>But how can we quantify what we see? A simple metric for distance between gene expression vectors between a given patient pair is the sum of the absolute difference between gene expression values. This can be formulated as follows: <span class="math inline">\(d_{AB}={\sum _{i=1}^{n}|e_{Ai}-e_{Bi}|}\)</span>, where <span class="math inline">\(d_{AB}\)</span> is the distance between patients A and B, and the <span class="math inline">\(e_{Ai}\)</span> and <span class="math inline">\(e_{Bi}\)</span> are expression values of the <span class="math inline">\(i\)</span>th gene for patients A and B. This distance metric is called the <strong>“Manhattan distance”</strong> or <strong>“L1 norm”</strong>. 
</p>
<p>Another distance metric uses the sum of squared distances and takes the square root of resulting value; this metric can be formulated as: <span class="math inline">\(d_{AB}={{\sqrt {\sum _{i=1}^{n}(e_{Ai}-e_{Bi})^{2}}}}\)</span>. This distance is called <strong>“Euclidean Distance”</strong> or <strong>“L2 norm”</strong>. This is usually the default distance metric for many clustering algorithms. Due to the squaring operation, values that are very different get higher contribution to the distance. Due to this, compared to the Manhattan distance, it can be affected more by outliers. But, generally if the outliers are rare, this distance metric works well.</p>
<p>The last metric we will introduce is the <strong>“correlation distance”</strong>. This is simply <span class="math inline">\(d_{AB}=1-\rho\)</span>, where <span class="math inline">\(\rho\)</span> is the Pearson correlation coefficient between two vectors; in our case those vectors are gene expression profiles of patients. Using this distance the gene expression vectors that have a similar pattern will have a small distance, whereas when the vectors have different patterns they will have a large distance. In this case, the linear correlation between vectors matters, although the scale of the vectors might be different.</p>
<p>Now let’s see how we can calculate these distances in R. First, we have our gene expression per patient table.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb191-1"></a>df</span></code></pre></div>
<pre><code>##          IRX4 OCT4 PAX6
## patient1   11   10    1
## patient2   13   13    3
## patient3    2    4   10
## patient4    1    3    9</code></pre>
<p>Next, we calculate the distance metrics using the <code>dist()</code> function and <code>1-cor()</code> expression.</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb193-1"></a><span class="kw">dist</span>(df,<span class="dt">method=</span><span class="st">&quot;manhattan&quot;</span>)</span></code></pre></div>
<pre><code>##          patient1 patient2 patient3
## patient2        7                  
## patient3       24       27         
## patient4       25       28        3</code></pre>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb195-1"></a><span class="kw">dist</span>(df,<span class="dt">method=</span><span class="st">&quot;euclidean&quot;</span>)</span></code></pre></div>
<pre><code>##           patient1  patient2  patient3
## patient2  4.123106                    
## patient3 14.071247 15.842980          
## patient4 14.594520 16.733201  1.732051</code></pre>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb197-1"></a><span class="kw">as.dist</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">cor</span>(<span class="kw">t</span>(df))) <span class="co"># correlation distance</span></span></code></pre></div>
<pre><code>##             patient1    patient2    patient3
## patient2 0.004129405                        
## patient3 1.988522468 1.970725343            
## patient4 1.988522468 1.970725343 0.000000000</code></pre>
<div id="scaling-before-calculating-the-distance" class="section level4">
<h4><span class="header-section-number">4.1.1.1</span> Scaling before calculating the distance</h4>
<p>Before we proceed to the clustering, there is one more thing we need to take care of. Should we normalize our data? The scale of the vectors in our expression matrix can affect the distance calculation. Gene expression tables might have some sort of normalization, so the values are in comparable scales. But somehow, if a gene’s expression values are on a much higher scale than the other genes, that gene will affect the distance more than others when using Euclidean or Manhattan distance. If that is the case we can scale the variables. The traditional way of scaling variables is to subtract their mean, and divide by their standard deviation, this operation is also called “standardization”. If this is done on all genes, each gene will have the same effect on distance measures. The decision to apply scaling ultimately depends on our data and what you want to achieve. If the gene expression values are previously normalized between patients, having genes that dominate the distance metric could have a biological meaning and therefore it may not be desirable to further scale variables. In R, the standardization is done via the <code>scale()</code> function. Here we scale the gene expression values.</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb199-1"></a>df</span></code></pre></div>
<pre><code>##          IRX4 OCT4 PAX6
## patient1   11   10    1
## patient2   13   13    3
## patient3    2    4   10
## patient4    1    3    9</code></pre>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb201-1"></a><span class="kw">scale</span>(df)</span></code></pre></div>
<pre><code>##                IRX4       OCT4       PAX6
## patient1  0.6932522  0.5212860 -1.0733721
## patient2  1.0194886  1.1468293 -0.6214260
## patient3 -0.7748113 -0.7298004  0.9603856
## patient4 -0.9379295 -0.9383149  0.7344125
## attr(,&quot;scaled:center&quot;)
## IRX4 OCT4 PAX6 
## 6.75 7.50 5.75 
## attr(,&quot;scaled:scale&quot;)
##     IRX4     OCT4     PAX6 
## 6.130525 4.795832 4.425306</code></pre>
</div>
</div>
<div id="hiearchical-clustering" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Hiearchical clustering</h3>
<p>This is one of the most ubiquitous clustering algorithms. Using this algorithm you can see the relationship of individual data points and relationships of clusters. This is achieved by successively joining small clusters to each other based on the inter-cluster distance. Eventually, you get a tree structure or a dendrogram that shows the relationship between the individual data points and clusters. The height of the dendrogram is the distance between clusters. Here we can show how to use this on our toy data set from four patients. The base function in R to do hierarchical clustering in <code>hclust()</code>. Below, we apply that function on Euclidean distances between patients. The resulting clustering tree or dendrogram is shown in Figure <a href="clustering-grouping-samples-based-on-their-similarity.html#fig:expPlot">4.1</a>.</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb203-1"></a>d=<span class="kw">dist</span>(df)</span>
<span id="cb203-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb203-2"></a>hc=<span class="kw">hclust</span>(d,<span class="dt">method=</span><span class="st">&quot;complete&quot;</span>)</span>
<span id="cb203-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb203-3"></a><span class="kw">plot</span>(hc)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:toyClust"></span>
<img src="04-unsupervisedLearning_files/figure-html/toyClust-1.png" alt="Dendrogram of distance matrix" width="50%" />
<p class="caption">
FIGURE 4.2: Dendrogram of distance matrix
</p>
</div>
<p>In the above code snippet, we have used the <code>method="complete"</code> argument without explaining it. The <code>method</code> argument defines the criteria that directs how the sub-clusters are merged. During clustering, starting with single-member clusters, the clusters are merged based on the distance between them. There are many different ways to define distance between clusters, and based on which definition you use, the hierarchical clustering results change. So the <code>method</code> argument controls that. There are a couple of values this argument can take; we list them and their description below:</p>
<ul>
<li><strong>“complete”</strong> stands for “Complete Linkage” and the distance between two clusters is defined as the largest distance between any members of the two clusters.</li>
<li><strong>“single”</strong> stands for “Single Linkage” and the distance between two clusters is defined as the smallest distance between any members of the two clusters.</li>
<li><strong>“average”</strong> stands for “Average Linkage” or more precisely the UPGMA (Unweighted Pair Group Method with Arithmetic Mean) method. In this case, the distance between two clusters is defined as the average distance between any members of the two clusters.</li>
<li><strong>“ward.D2”</strong> and <strong>“ward.D”</strong> stands for different implementations of Ward’s minimum variance method. This method aims to find compact, spherical clusters by selecting clusters to merge based on the change in the cluster variances. The clusters are merged if the increase in the combined variance over the sum of the cluster-specific variances is the minimum compared to alternative merging operations.</li>
</ul>
<p>In real life, we would get expression profiles from thousands of genes and we will typically have many more patients than our toy example. One such data set is gene expression values from 60 bone marrow samples of patients with one of the four main types of leukemia (ALL, AML, CLL, CML) or no-leukemia controls. We trimmed that data set down to the top 1000 most variable genes to be able to work with it more easily, since genes that are not very variable do not contribute much to the distances between patients. We will now use this data set to cluster the patients and display the values as a heatmap and a dendrogram. The heatmap shows the expression values of genes across patients in a color coded manner. The heatmap function, <code>pheatmap()</code>, that we will use performs the clustering as well. The matrix that contains gene expressions has the genes in the rows and the patients in the columns. Therefore, we will also use a column-side color code to mark the patients based on their leukemia type. For the hierarchical clustering, we will use Ward’s method designated by the <code>clustering_method</code> argument to the <code>pheatmap()</code> function. The resulting heatmap is shown in Figure <a href="clustering-grouping-samples-based-on-their-similarity.html#fig:heatmap1">4.3</a>. </p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-1"></a><span class="kw">library</span>(pheatmap)</span>
<span id="cb204-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-2"></a>expFile=<span class="kw">system.file</span>(<span class="st">&quot;extdata&quot;</span>,<span class="st">&quot;leukemiaExpressionSubset.rds&quot;</span>,</span>
<span id="cb204-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-3"></a>                    <span class="dt">package=</span><span class="st">&quot;compGenomRData&quot;</span>)</span>
<span id="cb204-4"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-4"></a>mat=<span class="kw">readRDS</span>(expFile)</span>
<span id="cb204-5"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-5"></a></span>
<span id="cb204-6"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-6"></a><span class="co"># set the leukemia type annotation for each sample</span></span>
<span id="cb204-7"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-7"></a>annotation_col =<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb204-8"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-8"></a>                    <span class="dt">LeukemiaType =</span><span class="kw">substr</span>(<span class="kw">colnames</span>(mat),<span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb204-9"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-9"></a><span class="kw">rownames</span>(annotation_col)=<span class="kw">colnames</span>(mat)</span>
<span id="cb204-10"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-10"></a>  </span>
<span id="cb204-11"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-11"></a></span>
<span id="cb204-12"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-12"></a><span class="kw">pheatmap</span>(mat,<span class="dt">show_rownames=</span><span class="ot">FALSE</span>,<span class="dt">show_colnames=</span><span class="ot">FALSE</span>,</span>
<span id="cb204-13"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-13"></a>         <span class="dt">annotation_col=</span>annotation_col,</span>
<span id="cb204-14"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-14"></a>         <span class="dt">scale =</span> <span class="st">&quot;none&quot;</span>,<span class="dt">clustering_method=</span><span class="st">&quot;ward.D2&quot;</span>,</span>
<span id="cb204-15"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb204-15"></a>         <span class="dt">clustering_distance_cols=</span><span class="st">&quot;euclidean&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:heatmap1"></span>
<img src="04-unsupervisedLearning_files/figure-html/heatmap1-1.png" alt="Heatmap of gene expression values from leukemia patients. Each column represents a patient. Columns are clustered using gene expression and color coded by disease type: ALL, AML, CLL, CML or no-leukemia " width="50%" />
<p class="caption">
FIGURE 4.3: Heatmap of gene expression values from leukemia patients. Each column represents a patient. Columns are clustered using gene expression and color coded by disease type: ALL, AML, CLL, CML or no-leukemia
</p>
</div>
<p>As we can observe in the heatmap, each cluster has a distinct set of expression values. The main clusters almost perfectly distinguish the leukemia types. Only one CML patient is clustered as a non-leukemia sample. This could mean that gene expression profiles are enough to classify leukemia type. More detailed analysis and experiments are needed to verify that, but by looking at this exploratory analysis we can decide where to focus our efforts next.</p>
<div id="where-to-cut-the-tree" class="section level4">
<h4><span class="header-section-number">4.1.2.1</span> Where to cut the tree ?</h4>
<p>The example above seems like a clear-cut example where we can pick clusters from the dendrogram by eye. This is mostly due to Ward’s method, where compact clusters are preferred. However, as is usually the case, we do not have patient labels and it would be difficult to tell which leaves (patients) in the dendrogram we should consider as part of the same cluster. In other words, how deep we should cut the dendrogram so that every patient sample still connected via the remaining sub-dendrograms constitute clusters. The <code>cutree()</code> function provides the functionality to output either desired number of clusters or clusters obtained from cutting the dendrogram at a certain height. Below, we will cluster the patients with hierarchical clustering using the default method “complete linkage” and cut the dendrogram at a certain height. In this case, you will also observe that, changing from Ward’s distance to complete linkage had an effect on clustering. Now the two clusters that are defined by Ward’s distance are closer to each other and harder to separate from each other, shown in Figure <a href="clustering-grouping-samples-based-on-their-similarity.html#fig:hclustNcut">4.4</a>.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb205-1"></a>hcl=<span class="kw">hclust</span>(<span class="kw">dist</span>(<span class="kw">t</span>(mat)))</span>
<span id="cb205-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb205-2"></a><span class="kw">plot</span>(hcl,<span class="dt">labels =</span> <span class="ot">FALSE</span>, <span class="dt">hang=</span> <span class="dv">-1</span>)</span>
<span id="cb205-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb205-3"></a><span class="kw">rect.hclust</span>(hcl, <span class="dt">h =</span> <span class="dv">80</span>, <span class="dt">border =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:hclustNcut"></span>
<img src="04-unsupervisedLearning_files/figure-html/hclustNcut-1.png" alt="Dendrogram of Leukemia patients clustered by hierarchical clustering. Rectangles show the cluster we will get if we cut the tree at `height=80`." width="50%" />
<p class="caption">
FIGURE 4.4: Dendrogram of Leukemia patients clustered by hierarchical clustering. Rectangles show the cluster we will get if we cut the tree at <code>height=80</code>.
</p>
</div>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb206-1"></a>clu.k5=<span class="kw">cutree</span>(hcl,<span class="dt">k=</span><span class="dv">5</span>) <span class="co"># cut tree so that there are 5 clusters</span></span>
<span id="cb206-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb206-2"></a></span>
<span id="cb206-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb206-3"></a>clu.h80=<span class="kw">cutree</span>(hcl,<span class="dt">h=</span><span class="dv">80</span>) <span class="co"># cut tree/dendrogram from height 80</span></span>
<span id="cb206-4"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb206-4"></a><span class="kw">table</span>(clu.k5) <span class="co"># number of samples for each cluster</span></span></code></pre></div>
<pre><code>## clu.k5
##  1  2  3  4  5 
## 12  3  9 12 24</code></pre>
<p>Apart from the arbitrary values for the height or the number of clusters, how can we define clusters more systematically? As this is a general question, we will show how to decide the optimal number of clusters later in this chapter.</p>
</div>
</div>
<div id="k-means-clustering" class="section level3">
<h3><span class="header-section-number">4.1.3</span> K-means clustering</h3>
<p>Another very common clustering algorithm is k-means. This method divides or partitions the data points, our working example patients, into a pre-determined, “k” number of clusters  <span class="citation">(Hartigan and Wong <a href="#ref-hartigan1979algorithm" role="doc-biblioref">1979</a>)</span>. Hence, these types of methods are generally called “partitioning” methods. The algorithm is initialized with randomly chosen <span class="math inline">\(k\)</span> centers or centroids. In a sense, a centroid is a data point with multiple values. In our working example, it is a hypothetical patient with gene expression values. But in the initialization phase, those gene expression values are chosen randomly within the boundaries of the gene expression distributions from real patients. As the next step in the algorithm, each patient is assigned to the closest centroid, and in the next iteration, centroids are set to the mean of values of the genes in the cluster. This process of setting centroids and assigning patients to the clusters repeats itself until the sum of squared distances to cluster centroids is minimized.</p>
<p>As you might see, the cluster algorithm starts with random initial centroids. This feature might yield different results for each run of the algorithm. We will now show how to use the k-means method on the gene expression data set. We will use <code>set.seed()</code> for reproducibility. In the wild, you might want to run this algorithm multiple times to see if your clustering results are stable.</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb208-1"></a><span class="kw">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb208-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb208-2"></a></span>
<span id="cb208-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb208-3"></a><span class="co"># we have to transpore the matrix t()</span></span>
<span id="cb208-4"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb208-4"></a><span class="co"># so that we calculate distances between patients</span></span>
<span id="cb208-5"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb208-5"></a>kclu=<span class="kw">kmeans</span>(<span class="kw">t</span>(mat),<span class="dt">centers=</span><span class="dv">5</span>)  </span>
<span id="cb208-6"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb208-6"></a></span>
<span id="cb208-7"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb208-7"></a><span class="co"># number of data points in each cluster</span></span>
<span id="cb208-8"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb208-8"></a><span class="kw">table</span>(kclu<span class="op">$</span>cluster)</span></code></pre></div>
<pre><code>## 
##  1  2  3  4  5 
## 12 14 11 12 11</code></pre>
<p>Now let us check the percentage of each leukemia type in each cluster. We can visualize this as a table. Looking at the table below, we see that each of the 5 clusters predominantly represents one of the 4 leukemia types or the control patients without leukemia.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb210-1"></a>type2kclu =<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb210-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb210-2"></a>                    <span class="dt">LeukemiaType =</span><span class="kw">substr</span>(<span class="kw">colnames</span>(mat),<span class="dv">1</span>,<span class="dv">3</span>),</span>
<span id="cb210-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb210-3"></a>                    <span class="dt">cluster=</span>kclu<span class="op">$</span>cluster)</span>
<span id="cb210-4"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb210-4"></a></span>
<span id="cb210-5"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb210-5"></a><span class="kw">table</span>(type2kclu)</span></code></pre></div>
<pre><code>##             cluster
## LeukemiaType  1  2  3  4  5
##          ALL 12  0  0  0  0
##          AML  0  1  0  0 11
##          CLL  0  0  0 12  0
##          CML  0  1 11  0  0
##          NoL  0 12  0  0  0</code></pre>
<p>Another related and maybe more robust algorithm is called <strong>“k-medoids”</strong> clustering <span class="citation">(Reynolds, Richards, Iglesia, et al. <a href="#ref-reynolds2006clustering" role="doc-biblioref">2006</a>)</span>. The procedure is almost identical to k-means clustering with a couple of differences.  In this case, centroids chosen are real data points in our case patients, and the metric we are trying to optimize in each iteration is based on the Manhattan distance to the centroid. In k-means this was based on the sum of squared distances, so Euclidean distance. Below we show how to use the k-medoids clustering function <code>pam()</code>  from the <code>cluster</code> package.</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb212-1"></a>kmclu=cluster<span class="op">::</span><span class="kw">pam</span>(<span class="kw">t</span>(mat),<span class="dt">k=</span><span class="dv">5</span>) <span class="co">#  cluster using k-medoids</span></span>
<span id="cb212-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb212-2"></a></span>
<span id="cb212-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb212-3"></a><span class="co"># make a data frame with Leukemia type and cluster id</span></span>
<span id="cb212-4"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb212-4"></a>type2kmclu =<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb212-5"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb212-5"></a>                    <span class="dt">LeukemiaType =</span><span class="kw">substr</span>(<span class="kw">colnames</span>(mat),<span class="dv">1</span>,<span class="dv">3</span>),</span>
<span id="cb212-6"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb212-6"></a>                    <span class="dt">cluster=</span>kmclu<span class="op">$</span>cluster)</span>
<span id="cb212-7"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb212-7"></a></span>
<span id="cb212-8"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb212-8"></a><span class="kw">table</span>(type2kmclu)</span></code></pre></div>
<pre><code>##             cluster
## LeukemiaType  1  2  3  4  5
##          ALL 12  0  0  0  0
##          AML  0 10  1  1  0
##          CLL  0  0  0  0 12
##          CML  0  0  0 12  0
##          NoL  0  0 12  0  0</code></pre>
<p>We cannot visualize the clustering from partitioning methods with a tree like we did for hierarchical clustering. Even if we can get the distances between patients the algorithm does not return the distances between clusters out of the box. However, if we had a way to visualize the distances between patients in 2 dimensions we could see the how patients and clusters relate to each other. It turns out that there is a way to compress between patient distances to a 2-dimensional plot. There are many ways to do this, and we introduce these dimension-reduction methods including the one we will use later in this chapter. For now, we are going to use a method called “multi-dimensional scaling” and plot the patients in a 2D plot color coded by their cluster assignments shown in Figure <a href="clustering-grouping-samples-based-on-their-similarity.html#fig:kmeansmds">4.5</a>. We will explain this method in more detail in the <a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#multi-dimensional-scaling">Multi-dimensional scaling</a> section below.</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-1"></a><span class="co"># Calculate distances</span></span>
<span id="cb214-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-2"></a>dists=<span class="kw">dist</span>(<span class="kw">t</span>(mat))</span>
<span id="cb214-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-3"></a></span>
<span id="cb214-4"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-4"></a><span class="co"># calculate MDS</span></span>
<span id="cb214-5"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-5"></a>mds=<span class="kw">cmdscale</span>(dists)</span>
<span id="cb214-6"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-6"></a></span>
<span id="cb214-7"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-7"></a><span class="co"># plot the patients in the 2D space</span></span>
<span id="cb214-8"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-8"></a><span class="kw">plot</span>(mds,<span class="dt">pch=</span><span class="dv">19</span>,<span class="dt">col=</span><span class="kw">rainbow</span>(<span class="dv">5</span>)[kclu<span class="op">$</span>cluster])</span>
<span id="cb214-9"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-9"></a></span>
<span id="cb214-10"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-10"></a><span class="co"># set the legend for cluster colors</span></span>
<span id="cb214-11"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-11"></a><span class="kw">legend</span>(<span class="st">&quot;bottomright&quot;</span>,</span>
<span id="cb214-12"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-12"></a>       <span class="dt">legend=</span><span class="kw">paste</span>(<span class="st">&quot;clu&quot;</span>,<span class="kw">unique</span>(kclu<span class="op">$</span>cluster)),</span>
<span id="cb214-13"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-13"></a>       <span class="dt">fill=</span><span class="kw">rainbow</span>(<span class="dv">5</span>)[<span class="kw">unique</span>(kclu<span class="op">$</span>cluster)],</span>
<span id="cb214-14"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb214-14"></a>       <span class="dt">border=</span><span class="ot">NA</span>,<span class="dt">box.col=</span><span class="ot">NA</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:kmeansmds"></span>
<img src="04-unsupervisedLearning_files/figure-html/kmeansmds-1.png" alt="K-means cluster memberships are shown in a multi-dimensional scaling plot" width="50%" />
<p class="caption">
FIGURE 4.5: K-means cluster memberships are shown in a multi-dimensional scaling plot
</p>
</div>
<p>The plot we obtained shows the separation between clusters. However, it does not do a great job showing the separation between clusters 3 and 4, which represent CML and “no leukemia” patients. We might need another dimension to properly visualize that separation. In addition, those two clusters were closely related in the hierarchical clustering as well.</p>
</div>
<div id="how-to-choose-k-the-number-of-clusters" class="section level3">
<h3><span class="header-section-number">4.1.4</span> How to choose “k”, the number of clusters</h3>
<p>Up to this point, we have avoided the question of selecting optimal number clusters. How do we know where to cut our dendrogram or which k to choose ?
First of all, this is a difficult question. Usually, clusters have different granularity. Some clusters are tight and compact and some are wide, and both these types of clusters can be in the same data set. When visualized, some large clusters may look like they may have sub-clusters. So should we consider the large cluster as one cluster or should we consider the sub-clusters as individual clusters? There are some metrics to help but there is no definite answer. We will show a couple of them below.</p>
<div id="silhouette" class="section level4">
<h4><span class="header-section-number">4.1.4.1</span> Silhouette</h4>
<p>One way to determine the quality of the clustering is to measure the expected self-similar nature of the points in a set of clusters. The silhouette value does just that and it is a measure of how similar a data point is to its own cluster compared to other clusters <span class="citation">(Rousseeuw <a href="#ref-rousseeuw1987silhouettes" role="doc-biblioref">1987</a>)</span>. The silhouette value ranges from -1 to +1, where values that are positive indicate that the data point is well matched to its own cluster, if the value is zero it is a borderline case, and if the value is minus it means that the data point might be mis-clustered because it is more similar to a neighboring cluster. If most data points have a high value, then the clustering is appropriate. Ideally, one can create many different clusterings with each with a different <span class="math inline">\(k\)</span> parameter indicating the number of clusters, and assess their appropriateness using the average
silhouette values. In R, silhouette values are referred to as silhouette widths in the documentation.</p>
<p>A silhouette value is calculated for each data point. In our working example, each patient will get silhouette values showing how well they are matched to their assigned clusters. Formally this calculated as follows. For each data point <span class="math inline">\(i\)</span>, we calculate <span class="math inline">\({\displaystyle a(i)}\)</span>, which denotes the average distance between <span class="math inline">\(i\)</span> and all other data points within the same cluster. This shows how well the point fits into that cluster. For the same data point, we also calculate <span class="math inline">\({\displaystyle b(i)}\)</span>, which denotes the lowest average distance of <span class="math inline">\({\displaystyle i}\)</span> to all points in any other cluster, of which <span class="math inline">\({\displaystyle i}\)</span> is not a member. The cluster with this lowest average <span class="math inline">\(b(i)\)</span> is the “neighboring cluster” of data point <span class="math inline">\({\displaystyle i}\)</span> since it is the next best fit cluster for that data point. Then, the silhouette value for a given data point is <span class="math inline">\(s(i) = \frac{b(i) - a(i)}{\max\{a(i),b(i)\}}\)</span>.</p>
<p>As described, this quantity is positive when <span class="math inline">\(b(i)\)</span> is high and <span class="math inline">\(a(i)\)</span> is low, meaning that the data point <span class="math inline">\(i\)</span> is self-similar to its cluster. And the silhouette value, <span class="math inline">\(s(i)\)</span>, is negative if it is more similar to its neighbors than its assigned cluster.</p>
<p>In R, we can calculate silhouette values using the <code>cluster::silhouette()</code> function. Below, we calculate the silhouette values for k-medoids clustering with the <code>pam()</code> function with <code>k=5</code>. The resulting silhouette values are shown in Figure <a href="clustering-grouping-samples-based-on-their-similarity.html#fig:sill">4.6</a>.</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb215-1"></a><span class="kw">library</span>(cluster)</span>
<span id="cb215-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb215-2"></a><span class="kw">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb215-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb215-3"></a>pamclu=cluster<span class="op">::</span><span class="kw">pam</span>(<span class="kw">t</span>(mat),<span class="dt">k=</span><span class="dv">5</span>)</span>
<span id="cb215-4"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb215-4"></a><span class="kw">plot</span>(<span class="kw">silhouette</span>(pamclu),<span class="dt">main=</span><span class="ot">NULL</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:sill"></span>
<img src="04-unsupervisedLearning_files/figure-html/sill-1.png" alt="Silhouette values for k-medoids with `k=5`" width="50%" />
<p class="caption">
FIGURE 4.6: Silhouette values for k-medoids with <code>k=5</code>
</p>
</div>
<p>Now, let us calculate the average silhouette value for different <span class="math inline">\(k\)</span> values and compare. We will use <code>sapply()</code> function to get average silhouette values across <span class="math inline">\(k\)</span> values between 2 and 7. Within <code>sapply()</code> there is an anonymous function that that does the clustering and calculates average silhouette values for each <span class="math inline">\(k\)</span>. The plot showing average silhouette values for different <span class="math inline">\(k\)</span> values is shown in Figure <a href="clustering-grouping-samples-based-on-their-similarity.html#fig:sillav">4.7</a>.</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb216-1"></a>Ks=<span class="kw">sapply</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">7</span>,</span>
<span id="cb216-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb216-2"></a>    <span class="cf">function</span>(i) </span>
<span id="cb216-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb216-3"></a>      <span class="kw">summary</span>(<span class="kw">silhouette</span>(<span class="kw">pam</span>(<span class="kw">t</span>(mat),<span class="dt">k=</span>i)))<span class="op">$</span>avg.width)</span>
<span id="cb216-4"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb216-4"></a><span class="kw">plot</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">7</span>,Ks,<span class="dt">xlab=</span><span class="st">&quot;k&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;av. silhouette&quot;</span>,<span class="dt">type=</span><span class="st">&quot;b&quot;</span>,</span>
<span id="cb216-5"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb216-5"></a>     <span class="dt">pch=</span><span class="dv">19</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:sillav"></span>
<img src="04-unsupervisedLearning_files/figure-html/sillav-1.png" alt="Average silhouette values for k-medoids clustering for `k` values between 2 and 7" width="40%" />
<p class="caption">
FIGURE 4.7: Average silhouette values for k-medoids clustering for <code>k</code> values between 2 and 7
</p>
</div>
<p>In this case, it seems the best value for <span class="math inline">\(k\)</span> is 4. The k-medoids function <code>pam()</code> will usually cluster CML and “no Leukemia” cases together when <code>k=4</code>, which are also related clusters according to the hierarchical clustering we did earlier.</p>
</div>
<div id="gap-statistic" class="section level4">
<h4><span class="header-section-number">4.1.4.2</span> Gap statistic</h4>
<p>As clustering aims to find self-similar data points, it would be reasonable to expect with the correct number of clusters the total within-cluster variation is minimized. Within-cluster variation for a single cluster can simply be defined as the sum of squares from the cluster mean, which in this case is the centroid we defined in the k-means algorithm. The total within-cluster variation is then the sum of within-cluster variations for each cluster. This can be formally defined as follows:</p>
<p><span class="math inline">\(\displaystyle W_k = \sum_{k=1}^K \sum_{\mathrm{x}_i \in C_k} (\mathrm{x}_i - \mu_k )^2\)</span></p>
<p>where <span class="math inline">\(\mathrm{x}_i\)</span> is a data point in cluster <span class="math inline">\(k\)</span>, and <span class="math inline">\(\mu_k\)</span> is the cluster mean, and <span class="math inline">\(W_k\)</span> is the total within-cluster variation quantity we described. However, the problem is that the variation quantity decreases with the number of clusters. The more centroids we have, the smaller the distances to the centroids become. A more reliable approach would be somehow calculating the expected variation from a reference null distribution and compare that to the observed variation for each <span class="math inline">\(k\)</span>. In the gap statistic approach, the expected distribution is calculated via sampling points from the boundaries of the original data and calculating within-cluster variation quantity for multiple rounds of sampling <span class="citation">(Tibshirani, Walther, and Hastie <a href="#ref-tibshirani2001estimating" role="doc-biblioref">2001</a>)</span>. This way we have an expectation about the variability when there is no clustering, and then compare that expected variation to the observed within-cluster variation. The expected variation should also go down with the increasing number of clusters, but for the optimal number of clusters, the expected variation will be furthest away from observed variation. This distance is called the <strong>“gap statistic”</strong> and defined as follows:
<span class="math inline">\(\displaystyle \mathrm{Gap}_n(k) = E_n^*\{\log W_k\} - \log W_k\)</span>, where <span class="math inline">\(E_n^*\{\log W_k\}\)</span> is the expected variation in log-scale under a sample size <span class="math inline">\(n\)</span> from the reference distribution and <span class="math inline">\(\log W_k\)</span> is the observed variation. Our aim is to choose the <span class="math inline">\(k\)</span> number of clusters that maximizes <span class="math inline">\(\mathrm{Gap}_n(k)\)</span>.</p>
<p>We can easily calculate the gap statistic with the <code>cluster::clusGap()</code> function. We will now use that function to calculate the gap statistic for our patient gene expression data. The resulting gap statistics are shown in Figure <a href="clustering-grouping-samples-based-on-their-similarity.html#fig:clusGap">4.8</a>.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-1"></a><span class="kw">library</span>(cluster)</span>
<span id="cb217-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-2"></a><span class="kw">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb217-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-3"></a><span class="co"># define the clustering function</span></span>
<span id="cb217-4"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-4"></a>pam1 &lt;-<span class="st"> </span><span class="cf">function</span>(x,k) </span>
<span id="cb217-5"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-5"></a>  <span class="kw">list</span>(<span class="dt">cluster =</span> <span class="kw">pam</span>(x,k, <span class="dt">cluster.only=</span><span class="ot">TRUE</span>))</span>
<span id="cb217-6"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-6"></a></span>
<span id="cb217-7"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-7"></a><span class="co"># calculate the gap statistic</span></span>
<span id="cb217-8"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-8"></a>pam.gap=<span class="st"> </span><span class="kw">clusGap</span>(<span class="kw">t</span>(mat), <span class="dt">FUN =</span> pam1, <span class="dt">K.max =</span> <span class="dv">8</span>,<span class="dt">B=</span><span class="dv">50</span>)</span>
<span id="cb217-9"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-9"></a></span>
<span id="cb217-10"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-10"></a><span class="co"># plot the gap statistic accross k values</span></span>
<span id="cb217-11"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb217-11"></a><span class="kw">plot</span>(pam.gap, <span class="dt">main =</span> <span class="st">&quot;Gap statistic for the &#39;Leukemia&#39; data&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:clusGap"></span>
<img src="04-unsupervisedLearning_files/figure-html/clusGap-1.png" alt="Gap statistic for clustering the leukemia dataset with k-medoids (pam) algorithm." width="50%" />
<p class="caption">
FIGURE 4.8: Gap statistic for clustering the leukemia dataset with k-medoids (pam) algorithm.
</p>
</div>
<p>In this case, the gap statistic shows that <span class="math inline">\(k=7\)</span> is the best if we take the maximum value as the best. However, after <span class="math inline">\(k=6\)</span>, the statistic has more or less a stable curve. This observation is incorporated into algorithms that can select the best <span class="math inline">\(k\)</span> value based on the gap statistic. A reasonable way is to take the simulation error (error bars in <a href="clustering-grouping-samples-based-on-their-similarity.html#fig:clusGap">4.8</a>) into account, and take the smallest <span class="math inline">\(k\)</span> whose gap statistic is larger or equal to the one of <span class="math inline">\(k+1\)</span> minus the simulation error. Formally written, we would pick the smallest <span class="math inline">\(k\)</span> satisfying the following condition: <span class="math inline">\(\mathrm{Gap}(k) \geq \mathrm{Gap}(k+1) - s_{k+1}\)</span>, where <span class="math inline">\(s_{k+1}\)</span> is the simulation error for <span class="math inline">\(\mathrm{Gap}(k+1)\)</span>.</p>
<p>Using this procedure gives us <span class="math inline">\(k=6\)</span> as the optimum number of clusters. Biologically, we know that there are 5 main patient categories but this does not mean there are no sub-categories or sub-types for the cancers we are looking at.</p>
</div>
<div id="other-methods" class="section level4">
<h4><span class="header-section-number">4.1.4.3</span> Other methods</h4>
<p>There are several other methods that provide insight into how many clusters. In fact, the package <code>NbClust</code> provides 30 different ways to determine the number of optimal clusters and can offer a voting mechanism to pick the best number. Below, we show how to use this function for some of the optimal number of cluster detection methods.</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb218-1"></a><span class="kw">library</span>(NbClust)</span>
<span id="cb218-2"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb218-2"></a>nb =<span class="st"> </span><span class="kw">NbClust</span>(<span class="dt">data=</span><span class="kw">t</span>(mat), </span>
<span id="cb218-3"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb218-3"></a>             <span class="dt">distance =</span> <span class="st">&quot;euclidean&quot;</span>, <span class="dt">min.nc =</span> <span class="dv">2</span>,</span>
<span id="cb218-4"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb218-4"></a>        <span class="dt">max.nc =</span> <span class="dv">7</span>, <span class="dt">method =</span> <span class="st">&quot;kmeans&quot;</span>,</span>
<span id="cb218-5"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb218-5"></a>        <span class="dt">index=</span><span class="kw">c</span>(<span class="st">&quot;kl&quot;</span>,<span class="st">&quot;ch&quot;</span>,<span class="st">&quot;cindex&quot;</span>,<span class="st">&quot;db&quot;</span>,<span class="st">&quot;silhouette&quot;</span>,</span>
<span id="cb218-6"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb218-6"></a>                <span class="st">&quot;duda&quot;</span>,<span class="st">&quot;pseudot2&quot;</span>,<span class="st">&quot;beale&quot;</span>,<span class="st">&quot;ratkowsky&quot;</span>,</span>
<span id="cb218-7"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb218-7"></a>                <span class="st">&quot;gap&quot;</span>,<span class="st">&quot;gamma&quot;</span>,<span class="st">&quot;mcclain&quot;</span>,<span class="st">&quot;gplus&quot;</span>,</span>
<span id="cb218-8"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb218-8"></a>                <span class="st">&quot;tau&quot;</span>,<span class="st">&quot;sdindex&quot;</span>,<span class="st">&quot;sdbw&quot;</span>))</span>
<span id="cb218-9"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb218-9"></a></span>
<span id="cb218-10"><a href="clustering-grouping-samples-based-on-their-similarity.html#cb218-10"></a><span class="kw">table</span>(nb<span class="op">$</span>Best.nc[<span class="dv">1</span>,]) <span class="co"># consensus seems to be 3 clusters </span></span></code></pre></div>
<p>However, readers should keep in mind that clustering is an exploratory technique. If you have solid labels for your data points, maybe clustering is just a sanity check, and you should just do predictive modeling instead. However, in biology there are rarely solid labels and things have different granularity. Take the leukemia patients case we have been using for example, it is known that leukemia types have subtypes and those sub-types that have different mutation profiles and consequently have different molecular signatures. Because of this, it is not surprising that some optimal cluster number techniques will find more clusters to be appropriate. On the other hand, CML (chronic myeloid leukemia) is a slow progressing disease and maybe their molecular signatures are closer to “no leukemia” patients, so clustering algorithms may confuse the two depending on what granularity they are operating with. It is always good to look at the heatmaps after clustering, if you have meaningful self-similar data points, even if the labels you have do not agree that there can be different clusters, you can perform downstream analysis to understand the sub-clusters better. As we have seen, we can estimate the optimal number of clusters but we cannot take that estimation as the absolute truth. Given more data points or a different set of expression signatures, you may have different optimal clusterings, or the supposed optimal clustering might overlook previously known sub-groups of your data.</p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-hartigan1979algorithm">
<p>Hartigan, and Wong. 1979. “Algorithm as 136: A K-Means Clustering Algorithm.” <em>Journal of the Royal Statistical Society. Series C (Applied Statistics)</em> 28 (1): 100–108.</p>
</div>
<div id="ref-reynolds2006clustering">
<p>Reynolds, Richards, Iglesia, and Rayward-Smith. 2006. “Clustering Rules: A Comparison of Partitioning and Hierarchical Clustering Algorithms.” <em>Journal of Mathematical Modelling and Algorithms</em> 5 (4): 475–504.</p>
</div>
<div id="ref-rousseeuw1987silhouettes">
<p>Rousseeuw. 1987. “Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis.” <em>Journal of Computational and Applied Mathematics</em> 20: 53–65.</p>
</div>
<div id="ref-tibshirani2001estimating">
<p>Tibshirani, Walther, and Hastie. 2001. “Estimating the Number of Clusters in a Data Set via the Gap Statistic.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 63 (2): 411–23.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="unsupervisedLearning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/compgenomr/book/edit/master/04-unsupervisedLearning.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
