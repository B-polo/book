<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.3 Relationship between variables: Linear models and correlation | Computational Genomics with R</title>
  <meta name="description" content="A guide to computationa genomics using R. The book covers fundemental topics with practical examples for an interdisciplinery audience" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="3.3 Relationship between variables: Linear models and correlation | Computational Genomics with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://compmgenomr.github.io/book/" />
  <meta property="og:image" content="https://compmgenomr.github.io/book/images/cover.jpg" />
  <meta property="og:description" content="A guide to computationa genomics using R. The book covers fundemental topics with practical examples for an interdisciplinery audience" />
  <meta name="github-repo" content="compgenomr/book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.3 Relationship between variables: Linear models and correlation | Computational Genomics with R" />
  
  <meta name="twitter:description" content="A guide to computationa genomics using R. The book covers fundemental topics with practical examples for an interdisciplinery audience" />
  <meta name="twitter:image" content="https://compmgenomr.github.io/book/images/cover.jpg" />

<meta name="author" content="Altuna Akalin" />


<meta name="date" content="2020-09-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="how-to-test-for-differences-between-samples.html"/>
<link rel="next" href="exercises-1.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-83786243-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-83786243-1');
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Computational Genomics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="who-is-this-book-for.html"><a href="who-is-this-book-for.html"><i class="fa fa-check"></i>Who is this book for?</a><ul>
<li class="chapter" data-level="" data-path="who-is-this-book-for.html"><a href="who-is-this-book-for.html#what-will-you-get-out-of-this"><i class="fa fa-check"></i>What will you get out of this?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="structure-of-the-book.html"><a href="structure-of-the-book.html"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="software-information-and-conventions.html"><a href="software-information-and-conventions.html"><i class="fa fa-check"></i>Software information and conventions</a><ul>
<li class="chapter" data-level="" data-path="software-information-and-conventions.html"><a href="software-information-and-conventions.html#assignment-operator-convention"><i class="fa fa-check"></i>Assignment operator convention</a></li>
<li class="chapter" data-level="" data-path="software-information-and-conventions.html"><a href="software-information-and-conventions.html#packages-needed-to-run-the-book-code"><i class="fa fa-check"></i>Packages needed to run the book code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-for-the-book.html"><a href="data-for-the-book.html"><i class="fa fa-check"></i>Data for the book</a></li>
<li class="chapter" data-level="" data-path="exercises-in-the-book.html"><a href="exercises-in-the-book.html"><i class="fa fa-check"></i>Exercises in the book</a></li>
<li class="chapter" data-level="" data-path="reproducibility-statement.html"><a href="reproducibility-statement.html"><i class="fa fa-check"></i>Reproducibility statement</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="how-to-contribute.html"><a href="how-to-contribute.html"><i class="fa fa-check"></i>How to contribute</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction to Genomics</a><ul>
<li class="chapter" data-level="1.1" data-path="genes-dna-and-central-dogma.html"><a href="genes-dna-and-central-dogma.html"><i class="fa fa-check"></i><b>1.1</b> Genes, DNA and central dogma</a><ul>
<li class="chapter" data-level="1.1.1" data-path="genes-dna-and-central-dogma.html"><a href="genes-dna-and-central-dogma.html#what-is-a-genome"><i class="fa fa-check"></i><b>1.1.1</b> What is a genome?</a></li>
<li class="chapter" data-level="1.1.2" data-path="genes-dna-and-central-dogma.html"><a href="genes-dna-and-central-dogma.html#what-is-a-gene"><i class="fa fa-check"></i><b>1.1.2</b> What is a gene?</a></li>
<li class="chapter" data-level="1.1.3" data-path="genes-dna-and-central-dogma.html"><a href="genes-dna-and-central-dogma.html#how-are-genes-controlled-transcriptional-and-post-transcriptional-regulation"><i class="fa fa-check"></i><b>1.1.3</b> How are genes controlled? Transcriptional and post-transcriptional regulation</a></li>
<li class="chapter" data-level="1.1.4" data-path="genes-dna-and-central-dogma.html"><a href="genes-dna-and-central-dogma.html#what-does-a-gene-look-like"><i class="fa fa-check"></i><b>1.1.4</b> What does a gene look like?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="elements-of-gene-regulation.html"><a href="elements-of-gene-regulation.html"><i class="fa fa-check"></i><b>1.2</b> Elements of gene regulation</a><ul>
<li class="chapter" data-level="1.2.1" data-path="elements-of-gene-regulation.html"><a href="elements-of-gene-regulation.html#transcriptional-regulation"><i class="fa fa-check"></i><b>1.2.1</b> Transcriptional regulation</a></li>
<li class="chapter" data-level="1.2.2" data-path="elements-of-gene-regulation.html"><a href="elements-of-gene-regulation.html#post-transcriptional-regulation"><i class="fa fa-check"></i><b>1.2.2</b> Post-transcriptional regulation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="shaping-the-genome-dna-mutation.html"><a href="shaping-the-genome-dna-mutation.html"><i class="fa fa-check"></i><b>1.3</b> Shaping the genome: DNA mutation</a></li>
<li class="chapter" data-level="1.4" data-path="high-throughput-experimental-methods-in-genomics.html"><a href="high-throughput-experimental-methods-in-genomics.html"><i class="fa fa-check"></i><b>1.4</b> High-throughput experimental methods in genomics</a><ul>
<li class="chapter" data-level="1.4.1" data-path="high-throughput-experimental-methods-in-genomics.html"><a href="high-throughput-experimental-methods-in-genomics.html#the-general-idea-behind-high-throughput-techniques"><i class="fa fa-check"></i><b>1.4.1</b> The general idea behind high-throughput techniques</a></li>
<li class="chapter" data-level="1.4.2" data-path="high-throughput-experimental-methods-in-genomics.html"><a href="high-throughput-experimental-methods-in-genomics.html#high-throughput-sequencing"><i class="fa fa-check"></i><b>1.4.2</b> High-throughput sequencing</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="visualization-and-data-repositories-for-genomics.html"><a href="visualization-and-data-repositories-for-genomics.html"><i class="fa fa-check"></i><b>1.5</b> Visualization and data repositories for genomics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Rintro.html"><a href="Rintro.html"><i class="fa fa-check"></i><b>2</b> Introduction to R for Genomic Data Analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html"><i class="fa fa-check"></i><b>2.1</b> Steps of (genomic) data analysis</a><ul>
<li class="chapter" data-level="2.1.1" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#data-collection"><i class="fa fa-check"></i><b>2.1.1</b> Data collection</a></li>
<li class="chapter" data-level="2.1.2" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#data-quality-check-and-cleaning"><i class="fa fa-check"></i><b>2.1.2</b> Data quality check and cleaning</a></li>
<li class="chapter" data-level="2.1.3" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#data-processing"><i class="fa fa-check"></i><b>2.1.3</b> Data processing</a></li>
<li class="chapter" data-level="2.1.4" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#exploratory-data-analysis-and-modeling"><i class="fa fa-check"></i><b>2.1.4</b> Exploratory data analysis and modeling</a></li>
<li class="chapter" data-level="2.1.5" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#visualization-and-reporting"><i class="fa fa-check"></i><b>2.1.5</b> Visualization and reporting</a></li>
<li class="chapter" data-level="2.1.6" data-path="steps-of-genomic-data-analysis.html"><a href="steps-of-genomic-data-analysis.html#why-use-r-for-genomics"><i class="fa fa-check"></i><b>2.1.6</b> Why use R for genomics ?</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html"><i class="fa fa-check"></i><b>2.2</b> Getting started with R</a><ul>
<li class="chapter" data-level="2.2.1" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#installing-packages"><i class="fa fa-check"></i><b>2.2.1</b> Installing packages</a></li>
<li class="chapter" data-level="2.2.2" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#installing-packages-in-custom-locations"><i class="fa fa-check"></i><b>2.2.2</b> Installing packages in custom locations</a></li>
<li class="chapter" data-level="2.2.3" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#getting-help-on-functions-and-packages"><i class="fa fa-check"></i><b>2.2.3</b> Getting help on functions and packages</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="computations-in-r.html"><a href="computations-in-r.html"><i class="fa fa-check"></i><b>2.3</b> Computations in R</a></li>
<li class="chapter" data-level="2.4" data-path="data-structures.html"><a href="data-structures.html"><i class="fa fa-check"></i><b>2.4</b> Data structures</a><ul>
<li class="chapter" data-level="2.4.1" data-path="data-structures.html"><a href="data-structures.html#vectors"><i class="fa fa-check"></i><b>2.4.1</b> Vectors</a></li>
<li class="chapter" data-level="2.4.2" data-path="data-structures.html"><a href="data-structures.html#matrices"><i class="fa fa-check"></i><b>2.4.2</b> Matrices</a></li>
<li class="chapter" data-level="2.4.3" data-path="data-structures.html"><a href="data-structures.html#data-frames"><i class="fa fa-check"></i><b>2.4.3</b> Data frames</a></li>
<li class="chapter" data-level="2.4.4" data-path="data-structures.html"><a href="data-structures.html#lists"><i class="fa fa-check"></i><b>2.4.4</b> Lists</a></li>
<li class="chapter" data-level="2.4.5" data-path="data-structures.html"><a href="data-structures.html#factors"><i class="fa fa-check"></i><b>2.4.5</b> Factors</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="data-types.html"><a href="data-types.html"><i class="fa fa-check"></i><b>2.5</b> Data types</a></li>
<li class="chapter" data-level="2.6" data-path="reading-and-writing-data.html"><a href="reading-and-writing-data.html"><i class="fa fa-check"></i><b>2.6</b> Reading and writing data</a><ul>
<li class="chapter" data-level="2.6.1" data-path="reading-and-writing-data.html"><a href="reading-and-writing-data.html#reading-large-files"><i class="fa fa-check"></i><b>2.6.1</b> Reading large files</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="plotting-in-r-with-base-graphics.html"><a href="plotting-in-r-with-base-graphics.html"><i class="fa fa-check"></i><b>2.7</b> Plotting in R with base graphics</a><ul>
<li class="chapter" data-level="2.7.1" data-path="plotting-in-r-with-base-graphics.html"><a href="plotting-in-r-with-base-graphics.html#combining-multiple-plots"><i class="fa fa-check"></i><b>2.7.1</b> Combining multiple plots</a></li>
<li class="chapter" data-level="2.7.2" data-path="plotting-in-r-with-base-graphics.html"><a href="plotting-in-r-with-base-graphics.html#saving-plots"><i class="fa fa-check"></i><b>2.7.2</b> Saving plots</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="plotting-in-r-with-ggplot2.html"><a href="plotting-in-r-with-ggplot2.html"><i class="fa fa-check"></i><b>2.8</b> Plotting in R with ggplot2</a><ul>
<li class="chapter" data-level="2.8.1" data-path="plotting-in-r-with-ggplot2.html"><a href="plotting-in-r-with-ggplot2.html#combining-multiple-plots-1"><i class="fa fa-check"></i><b>2.8.1</b> Combining multiple plots</a></li>
<li class="chapter" data-level="2.8.2" data-path="plotting-in-r-with-ggplot2.html"><a href="plotting-in-r-with-ggplot2.html#ggplot2-and-tidyverse"><i class="fa fa-check"></i><b>2.8.2</b> ggplot2 and tidyverse</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="functions-and-control-structures-for-ifelse-etc-.html"><a href="functions-and-control-structures-for-ifelse-etc-.html"><i class="fa fa-check"></i><b>2.9</b> Functions and control structures (for, if/else etc.)</a><ul>
<li class="chapter" data-level="2.9.1" data-path="functions-and-control-structures-for-ifelse-etc-.html"><a href="functions-and-control-structures-for-ifelse-etc-.html#user-defined-functions"><i class="fa fa-check"></i><b>2.9.1</b> User-defined functions</a></li>
<li class="chapter" data-level="2.9.2" data-path="functions-and-control-structures-for-ifelse-etc-.html"><a href="functions-and-control-structures-for-ifelse-etc-.html#loops-and-looping-structures-in-r"><i class="fa fa-check"></i><b>2.9.2</b> Loops and looping structures in R</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.10</b> Exercises</a><ul>
<li class="chapter" data-level="2.10.1" data-path="exercises.html"><a href="exercises.html#computations-in-r-1"><i class="fa fa-check"></i><b>2.10.1</b> Computations in R</a></li>
<li class="chapter" data-level="2.10.2" data-path="exercises.html"><a href="exercises.html#data-structures-in-r"><i class="fa fa-check"></i><b>2.10.2</b> Data structures in R</a></li>
<li class="chapter" data-level="2.10.3" data-path="exercises.html"><a href="exercises.html#reading-in-and-writing-data-out-in-r"><i class="fa fa-check"></i><b>2.10.3</b> Reading in and writing data out in R</a></li>
<li class="chapter" data-level="2.10.4" data-path="exercises.html"><a href="exercises.html#plotting-in-r"><i class="fa fa-check"></i><b>2.10.4</b> Plotting in R</a></li>
<li class="chapter" data-level="2.10.5" data-path="exercises.html"><a href="exercises.html#functions-and-control-structures-for-ifelse-etc.-1"><i class="fa fa-check"></i><b>2.10.5</b> Functions and control structures (for, if/else, etc.)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stats.html"><a href="stats.html"><i class="fa fa-check"></i><b>3</b> Statistics for Genomics</a><ul>
<li class="chapter" data-level="3.1" data-path="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html"><a href="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html"><i class="fa fa-check"></i><b>3.1</b> How to summarize collection of data points: The idea behind statistical distributions</a><ul>
<li class="chapter" data-level="3.1.1" data-path="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html"><a href="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html#describing-the-central-tendency-mean-and-median"><i class="fa fa-check"></i><b>3.1.1</b> Describing the central tendency: Mean and median</a></li>
<li class="chapter" data-level="3.1.2" data-path="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html"><a href="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html#describing-the-spread-measurements-of-variation"><i class="fa fa-check"></i><b>3.1.2</b> Describing the spread: Measurements of variation</a></li>
<li class="chapter" data-level="3.1.3" data-path="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html"><a href="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html#precision-of-estimates-confidence-intervals"><i class="fa fa-check"></i><b>3.1.3</b> Precision of estimates: Confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="how-to-test-for-differences-between-samples.html"><a href="how-to-test-for-differences-between-samples.html"><i class="fa fa-check"></i><b>3.2</b> How to test for differences between samples</a><ul>
<li class="chapter" data-level="3.2.1" data-path="how-to-test-for-differences-between-samples.html"><a href="how-to-test-for-differences-between-samples.html#randomization-based-testing-for-difference-of-the-means"><i class="fa fa-check"></i><b>3.2.1</b> Randomization-based testing for difference of the means</a></li>
<li class="chapter" data-level="3.2.2" data-path="how-to-test-for-differences-between-samples.html"><a href="how-to-test-for-differences-between-samples.html#using-t-test-for-difference-of-the-means-between-two-samples"><i class="fa fa-check"></i><b>3.2.2</b> Using t-test for difference of the means between two samples</a></li>
<li class="chapter" data-level="3.2.3" data-path="how-to-test-for-differences-between-samples.html"><a href="how-to-test-for-differences-between-samples.html#multiple-testing-correction"><i class="fa fa-check"></i><b>3.2.3</b> Multiple testing correction</a></li>
<li class="chapter" data-level="3.2.4" data-path="how-to-test-for-differences-between-samples.html"><a href="how-to-test-for-differences-between-samples.html#moderated-t-tests-using-information-from-multiple-comparisons"><i class="fa fa-check"></i><b>3.2.4</b> Moderated t-tests: Using information from multiple comparisons</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html"><i class="fa fa-check"></i><b>3.3</b> Relationship between variables: Linear models and correlation</a><ul>
<li class="chapter" data-level="3.3.1" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html#how-to-fit-a-line"><i class="fa fa-check"></i><b>3.3.1</b> How to fit a line</a></li>
<li class="chapter" data-level="3.3.2" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html#how-to-estimate-the-error-of-the-coefficients"><i class="fa fa-check"></i><b>3.3.2</b> How to estimate the error of the coefficients</a></li>
<li class="chapter" data-level="3.3.3" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html#accuracy-of-the-model"><i class="fa fa-check"></i><b>3.3.3</b> Accuracy of the model</a></li>
<li class="chapter" data-level="3.3.4" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html#regression-with-categorical-variables"><i class="fa fa-check"></i><b>3.3.4</b> Regression with categorical variables</a></li>
<li class="chapter" data-level="3.3.5" data-path="relationship-between-variables-linear-models-and-correlation.html"><a href="relationship-between-variables-linear-models-and-correlation.html#regression-pitfalls"><i class="fa fa-check"></i><b>3.3.5</b> Regression pitfalls</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>3.4</b> Exercises</a><ul>
<li class="chapter" data-level="3.4.1" data-path="exercises-1.html"><a href="exercises-1.html#how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions-1"><i class="fa fa-check"></i><b>3.4.1</b> How to summarize collection of data points: The idea behind statistical distributions</a></li>
<li class="chapter" data-level="3.4.2" data-path="exercises-1.html"><a href="exercises-1.html#how-to-test-for-differences-in-samples"><i class="fa fa-check"></i><b>3.4.2</b> How to test for differences in samples</a></li>
<li class="chapter" data-level="3.4.3" data-path="exercises-1.html"><a href="exercises-1.html#relationship-between-variables-linear-models-and-correlation-1"><i class="fa fa-check"></i><b>3.4.3</b> Relationship between variables: Linear models and correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="unsupervisedLearning.html"><a href="unsupervisedLearning.html"><i class="fa fa-check"></i><b>4</b> Exploratory Data Analysis with Unsupervised Machine Learning</a><ul>
<li class="chapter" data-level="4.1" data-path="clustering-grouping-samples-based-on-their-similarity.html"><a href="clustering-grouping-samples-based-on-their-similarity.html"><i class="fa fa-check"></i><b>4.1</b> Clustering: Grouping samples based on their similarity</a><ul>
<li class="chapter" data-level="4.1.1" data-path="clustering-grouping-samples-based-on-their-similarity.html"><a href="clustering-grouping-samples-based-on-their-similarity.html#distance-metrics"><i class="fa fa-check"></i><b>4.1.1</b> Distance metrics</a></li>
<li class="chapter" data-level="4.1.2" data-path="clustering-grouping-samples-based-on-their-similarity.html"><a href="clustering-grouping-samples-based-on-their-similarity.html#hiearchical-clustering"><i class="fa fa-check"></i><b>4.1.2</b> Hiearchical clustering</a></li>
<li class="chapter" data-level="4.1.3" data-path="clustering-grouping-samples-based-on-their-similarity.html"><a href="clustering-grouping-samples-based-on-their-similarity.html#k-means-clustering"><i class="fa fa-check"></i><b>4.1.3</b> K-means clustering</a></li>
<li class="chapter" data-level="4.1.4" data-path="clustering-grouping-samples-based-on-their-similarity.html"><a href="clustering-grouping-samples-based-on-their-similarity.html#how-to-choose-k-the-number-of-clusters"><i class="fa fa-check"></i><b>4.1.4</b> How to choose “k”, the number of clusters</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><i class="fa fa-check"></i><b>4.2</b> Dimensionality reduction techniques: Visualizing complex data sets in 2D</a><ul>
<li class="chapter" data-level="4.2.1" data-path="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#principal-component-analysis"><i class="fa fa-check"></i><b>4.2.1</b> Principal component analysis</a></li>
<li class="chapter" data-level="4.2.2" data-path="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#other-matrix-factorization-methods-for-dimensionality-reduction"><i class="fa fa-check"></i><b>4.2.2</b> Other matrix factorization methods for dimensionality reduction</a></li>
<li class="chapter" data-level="4.2.3" data-path="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#multi-dimensional-scaling"><i class="fa fa-check"></i><b>4.2.3</b> Multi-dimensional scaling</a></li>
<li class="chapter" data-level="4.2.4" data-path="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html"><a href="dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#t-distributed-stochastic-neighbor-embedding-t-sne"><i class="fa fa-check"></i><b>4.2.4</b> t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>4.3</b> Exercises</a><ul>
<li class="chapter" data-level="4.3.1" data-path="exercises-2.html"><a href="exercises-2.html#clustering"><i class="fa fa-check"></i><b>4.3.1</b> Clustering</a></li>
<li class="chapter" data-level="4.3.2" data-path="exercises-2.html"><a href="exercises-2.html#dimension-reduction"><i class="fa fa-check"></i><b>4.3.2</b> Dimension reduction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="supervisedLearning.html"><a href="supervisedLearning.html"><i class="fa fa-check"></i><b>5</b> Predictive Modeling with Supervised Machine Learning</a><ul>
<li class="chapter" data-level="5.1" data-path="how-are-machine-learning-models-fit.html"><a href="how-are-machine-learning-models-fit.html"><i class="fa fa-check"></i><b>5.1</b> How are machine learning models fit?</a><ul>
<li class="chapter" data-level="5.1.1" data-path="how-are-machine-learning-models-fit.html"><a href="how-are-machine-learning-models-fit.html#machine-learning-vs.-statistics"><i class="fa fa-check"></i><b>5.1.1</b> Machine learning vs. statistics</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="steps-in-supervised-machine-learning.html"><a href="steps-in-supervised-machine-learning.html"><i class="fa fa-check"></i><b>5.2</b> Steps in supervised machine learning</a></li>
<li class="chapter" data-level="5.3" data-path="use-case-disease-subtype-from-genomics-data.html"><a href="use-case-disease-subtype-from-genomics-data.html"><i class="fa fa-check"></i><b>5.3</b> Use case: Disease subtype from genomics data</a></li>
<li class="chapter" data-level="5.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html"><i class="fa fa-check"></i><b>5.4</b> Data preprocessing</a><ul>
<li class="chapter" data-level="5.4.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#data-transformation"><i class="fa fa-check"></i><b>5.4.1</b> Data transformation</a></li>
<li class="chapter" data-level="5.4.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#filtering-data-and-scaling"><i class="fa fa-check"></i><b>5.4.2</b> Filtering data and scaling</a></li>
<li class="chapter" data-level="5.4.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#dealing-with-missing-values"><i class="fa fa-check"></i><b>5.4.3</b> Dealing with missing values</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="splitting-the-data.html"><a href="splitting-the-data.html"><i class="fa fa-check"></i><b>5.5</b> Splitting the data</a><ul>
<li class="chapter" data-level="5.5.1" data-path="splitting-the-data.html"><a href="splitting-the-data.html#holdout-test-dataset"><i class="fa fa-check"></i><b>5.5.1</b> Holdout test dataset</a></li>
<li class="chapter" data-level="5.5.2" data-path="splitting-the-data.html"><a href="splitting-the-data.html#cross-validation"><i class="fa fa-check"></i><b>5.5.2</b> Cross-validation</a></li>
<li class="chapter" data-level="5.5.3" data-path="splitting-the-data.html"><a href="splitting-the-data.html#bootstrap-resampling"><i class="fa fa-check"></i><b>5.5.3</b> Bootstrap resampling</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="predicting-the-subtype-with-k-nearest-neighbors.html"><a href="predicting-the-subtype-with-k-nearest-neighbors.html"><i class="fa fa-check"></i><b>5.6</b> Predicting the subtype with k-nearest neighbors</a></li>
<li class="chapter" data-level="5.7" data-path="assessing-the-performance-of-our-model.html"><a href="assessing-the-performance-of-our-model.html"><i class="fa fa-check"></i><b>5.7</b> Assessing the performance of our model</a><ul>
<li class="chapter" data-level="5.7.1" data-path="assessing-the-performance-of-our-model.html"><a href="assessing-the-performance-of-our-model.html#receiver-operating-characteristic-roc-curves"><i class="fa fa-check"></i><b>5.7.1</b> Receiver Operating Characteristic (ROC) curves</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="model-tuning-and-avoiding-overfitting.html"><a href="model-tuning-and-avoiding-overfitting.html"><i class="fa fa-check"></i><b>5.8</b> Model tuning and avoiding overfitting</a><ul>
<li class="chapter" data-level="5.8.1" data-path="model-tuning-and-avoiding-overfitting.html"><a href="model-tuning-and-avoiding-overfitting.html#model-complexity-and-bias-variance-trade-off"><i class="fa fa-check"></i><b>5.8.1</b> Model complexity and bias variance trade-off</a></li>
<li class="chapter" data-level="5.8.2" data-path="model-tuning-and-avoiding-overfitting.html"><a href="model-tuning-and-avoiding-overfitting.html#data-split-strategies-for-model-tuning-and-testing"><i class="fa fa-check"></i><b>5.8.2</b> Data split strategies for model tuning and testing</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="variable-importance.html"><a href="variable-importance.html"><i class="fa fa-check"></i><b>5.9</b> Variable importance</a></li>
<li class="chapter" data-level="5.10" data-path="how-to-deal-with-class-imbalance.html"><a href="how-to-deal-with-class-imbalance.html"><i class="fa fa-check"></i><b>5.10</b> How to deal with class imbalance</a><ul>
<li class="chapter" data-level="5.10.1" data-path="how-to-deal-with-class-imbalance.html"><a href="how-to-deal-with-class-imbalance.html#sampling-for-class-balance"><i class="fa fa-check"></i><b>5.10.1</b> Sampling for class balance</a></li>
<li class="chapter" data-level="5.10.2" data-path="how-to-deal-with-class-imbalance.html"><a href="how-to-deal-with-class-imbalance.html#altering-case-weights"><i class="fa fa-check"></i><b>5.10.2</b> Altering case weights</a></li>
<li class="chapter" data-level="5.10.3" data-path="how-to-deal-with-class-imbalance.html"><a href="how-to-deal-with-class-imbalance.html#selecting-different-classification-score-cutoffs"><i class="fa fa-check"></i><b>5.10.3</b> Selecting different classification score cutoffs</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="dealing-with-correlated-predictors.html"><a href="dealing-with-correlated-predictors.html"><i class="fa fa-check"></i><b>5.11</b> Dealing with correlated predictors</a></li>
<li class="chapter" data-level="5.12" data-path="trees-and-forests-random-forests-in-action.html"><a href="trees-and-forests-random-forests-in-action.html"><i class="fa fa-check"></i><b>5.12</b> Trees and forests: Random forests in action</a><ul>
<li class="chapter" data-level="5.12.1" data-path="trees-and-forests-random-forests-in-action.html"><a href="trees-and-forests-random-forests-in-action.html#decision-trees"><i class="fa fa-check"></i><b>5.12.1</b> Decision trees</a></li>
<li class="chapter" data-level="5.12.2" data-path="trees-and-forests-random-forests-in-action.html"><a href="trees-and-forests-random-forests-in-action.html#trees-to-forests"><i class="fa fa-check"></i><b>5.12.2</b> Trees to forests</a></li>
<li class="chapter" data-level="5.12.3" data-path="trees-and-forests-random-forests-in-action.html"><a href="trees-and-forests-random-forests-in-action.html#variable-importance-1"><i class="fa fa-check"></i><b>5.12.3</b> Variable importance</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="logistic-regression-and-regularization.html"><a href="logistic-regression-and-regularization.html"><i class="fa fa-check"></i><b>5.13</b> Logistic regression and regularization</a><ul>
<li class="chapter" data-level="5.13.1" data-path="logistic-regression-and-regularization.html"><a href="logistic-regression-and-regularization.html#regularization-in-order-to-avoid-overfitting"><i class="fa fa-check"></i><b>5.13.1</b> Regularization in order to avoid overfitting</a></li>
<li class="chapter" data-level="5.13.2" data-path="logistic-regression-and-regularization.html"><a href="logistic-regression-and-regularization.html#variable-importance-2"><i class="fa fa-check"></i><b>5.13.2</b> Variable importance</a></li>
</ul></li>
<li class="chapter" data-level="5.14" data-path="other-supervised-algorithms.html"><a href="other-supervised-algorithms.html"><i class="fa fa-check"></i><b>5.14</b> Other supervised algorithms</a><ul>
<li class="chapter" data-level="5.14.1" data-path="other-supervised-algorithms.html"><a href="other-supervised-algorithms.html#gradient-boosting"><i class="fa fa-check"></i><b>5.14.1</b> Gradient boosting</a></li>
<li class="chapter" data-level="5.14.2" data-path="other-supervised-algorithms.html"><a href="other-supervised-algorithms.html#support-vector-machines-svm"><i class="fa fa-check"></i><b>5.14.2</b> Support Vector Machines (SVM)</a></li>
<li class="chapter" data-level="5.14.3" data-path="other-supervised-algorithms.html"><a href="other-supervised-algorithms.html#neural-networks-and-deep-versions-of-it"><i class="fa fa-check"></i><b>5.14.3</b> Neural networks and deep versions of it</a></li>
<li class="chapter" data-level="5.14.4" data-path="other-supervised-algorithms.html"><a href="other-supervised-algorithms.html#ensemble-learning"><i class="fa fa-check"></i><b>5.14.4</b> Ensemble learning</a></li>
</ul></li>
<li class="chapter" data-level="5.15" data-path="predicting-continuous-variables-regression-with-machine-learning.html"><a href="predicting-continuous-variables-regression-with-machine-learning.html"><i class="fa fa-check"></i><b>5.15</b> Predicting continuous variables: Regression with machine learning</a><ul>
<li class="chapter" data-level="5.15.1" data-path="predicting-continuous-variables-regression-with-machine-learning.html"><a href="predicting-continuous-variables-regression-with-machine-learning.html#use-case-predicting-age-from-dna-methylation"><i class="fa fa-check"></i><b>5.15.1</b> Use case: Predicting age from DNA methylation</a></li>
<li class="chapter" data-level="5.15.2" data-path="predicting-continuous-variables-regression-with-machine-learning.html"><a href="predicting-continuous-variables-regression-with-machine-learning.html#reading-and-processing-the-data"><i class="fa fa-check"></i><b>5.15.2</b> Reading and processing the data</a></li>
<li class="chapter" data-level="5.15.3" data-path="predicting-continuous-variables-regression-with-machine-learning.html"><a href="predicting-continuous-variables-regression-with-machine-learning.html#running-random-forest-regression"><i class="fa fa-check"></i><b>5.15.3</b> Running random forest regression</a></li>
</ul></li>
<li class="chapter" data-level="5.16" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>5.16</b> Exercises</a><ul>
<li class="chapter" data-level="5.16.1" data-path="exercises-3.html"><a href="exercises-3.html#classification"><i class="fa fa-check"></i><b>5.16.1</b> Classification</a></li>
<li class="chapter" data-level="5.16.2" data-path="exercises-3.html"><a href="exercises-3.html#regression"><i class="fa fa-check"></i><b>5.16.2</b> Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="genomicIntervals.html"><a href="genomicIntervals.html"><i class="fa fa-check"></i><b>6</b> Operations on Genomic Intervals and Genome Arithmetic</a><ul>
<li class="chapter" data-level="6.1" data-path="operations-on-genomic-intervals-with-genomicranges-package.html"><a href="operations-on-genomic-intervals-with-genomicranges-package.html"><i class="fa fa-check"></i><b>6.1</b> Operations on genomic intervals with <code>GenomicRanges</code> package</a><ul>
<li class="chapter" data-level="6.1.1" data-path="operations-on-genomic-intervals-with-genomicranges-package.html"><a href="operations-on-genomic-intervals-with-genomicranges-package.html#how-to-create-and-manipulate-a-granges-object"><i class="fa fa-check"></i><b>6.1.1</b> How to create and manipulate a GRanges object</a></li>
<li class="chapter" data-level="6.1.2" data-path="operations-on-genomic-intervals-with-genomicranges-package.html"><a href="operations-on-genomic-intervals-with-genomicranges-package.html#getting-genomic-regions-into-r-as-granges-objects"><i class="fa fa-check"></i><b>6.1.2</b> Getting genomic regions into R as GRanges objects</a></li>
<li class="chapter" data-level="6.1.3" data-path="operations-on-genomic-intervals-with-genomicranges-package.html"><a href="operations-on-genomic-intervals-with-genomicranges-package.html#finding-regions-that-dodo-not-overlap-with-another-set-of-regions"><i class="fa fa-check"></i><b>6.1.3</b> Finding regions that do/do not overlap with another set of regions</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="dealing-with-mapped-high-throughput-sequencing-reads.html"><a href="dealing-with-mapped-high-throughput-sequencing-reads.html"><i class="fa fa-check"></i><b>6.2</b> Dealing with mapped high-throughput sequencing reads</a><ul>
<li class="chapter" data-level="6.2.1" data-path="dealing-with-mapped-high-throughput-sequencing-reads.html"><a href="dealing-with-mapped-high-throughput-sequencing-reads.html#counting-mapped-reads-for-a-set-of-regions"><i class="fa fa-check"></i><b>6.2.1</b> Counting mapped reads for a set of regions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="dealing-with-continuous-scores-over-the-genome.html"><a href="dealing-with-continuous-scores-over-the-genome.html"><i class="fa fa-check"></i><b>6.3</b> Dealing with continuous scores over the genome</a><ul>
<li class="chapter" data-level="6.3.1" data-path="dealing-with-continuous-scores-over-the-genome.html"><a href="dealing-with-continuous-scores-over-the-genome.html#extracting-subsections-of-rle-and-rlelist-objects"><i class="fa fa-check"></i><b>6.3.1</b> Extracting subsections of Rle and RleList objects</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="genomic-intervals-with-more-information-summarizedexperiment-class.html"><a href="genomic-intervals-with-more-information-summarizedexperiment-class.html"><i class="fa fa-check"></i><b>6.4</b> Genomic intervals with more information: SummarizedExperiment class</a><ul>
<li class="chapter" data-level="6.4.1" data-path="genomic-intervals-with-more-information-summarizedexperiment-class.html"><a href="genomic-intervals-with-more-information-summarizedexperiment-class.html#create-a-summarizedexperiment-object"><i class="fa fa-check"></i><b>6.4.1</b> Create a SummarizedExperiment object</a></li>
<li class="chapter" data-level="6.4.2" data-path="genomic-intervals-with-more-information-summarizedexperiment-class.html"><a href="genomic-intervals-with-more-information-summarizedexperiment-class.html#subset-and-manipulate-the-summarizedexperiment-object"><i class="fa fa-check"></i><b>6.4.2</b> Subset and manipulate the SummarizedExperiment object</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="visualizing-and-summarizing-genomic-intervals.html"><a href="visualizing-and-summarizing-genomic-intervals.html"><i class="fa fa-check"></i><b>6.5</b> Visualizing and summarizing genomic intervals</a><ul>
<li class="chapter" data-level="6.5.1" data-path="visualizing-and-summarizing-genomic-intervals.html"><a href="visualizing-and-summarizing-genomic-intervals.html#visualizing-intervals-on-a-locus-of-interest"><i class="fa fa-check"></i><b>6.5.1</b> Visualizing intervals on a locus of interest</a></li>
<li class="chapter" data-level="6.5.2" data-path="visualizing-and-summarizing-genomic-intervals.html"><a href="visualizing-and-summarizing-genomic-intervals.html#summaries-of-genomic-intervals-on-multiple-loci"><i class="fa fa-check"></i><b>6.5.2</b> Summaries of genomic intervals on multiple loci</a></li>
<li class="chapter" data-level="6.5.3" data-path="visualizing-and-summarizing-genomic-intervals.html"><a href="visualizing-and-summarizing-genomic-intervals.html#making-karyograms-and-circos-plots"><i class="fa fa-check"></i><b>6.5.3</b> Making karyograms and circos plots</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>6.6</b> Exercises</a><ul>
<li class="chapter" data-level="6.6.1" data-path="exercises-4.html"><a href="exercises-4.html#operations-on-genomic-intervals-with-the-genomicranges-package"><i class="fa fa-check"></i><b>6.6.1</b> Operations on genomic intervals with the <code>GenomicRanges</code> package</a></li>
<li class="chapter" data-level="6.6.2" data-path="exercises-4.html"><a href="exercises-4.html#dealing-with-mapped-high-throughput-sequencing-reads-1"><i class="fa fa-check"></i><b>6.6.2</b> Dealing with mapped high-throughput sequencing reads</a></li>
<li class="chapter" data-level="6.6.3" data-path="exercises-4.html"><a href="exercises-4.html#dealing-with-contiguous-scores-over-the-genome"><i class="fa fa-check"></i><b>6.6.3</b> Dealing with contiguous scores over the genome</a></li>
<li class="chapter" data-level="6.6.4" data-path="exercises-4.html"><a href="exercises-4.html#visualizing-and-summarizing-genomic-intervals-1"><i class="fa fa-check"></i><b>6.6.4</b> Visualizing and summarizing genomic intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="processingReads.html"><a href="processingReads.html"><i class="fa fa-check"></i><b>7</b> Quality Check, Processing and Alignment of High-throughput Sequencing Reads</a><ul>
<li class="chapter" data-level="7.1" data-path="fasta-and-fastq-formats.html"><a href="fasta-and-fastq-formats.html"><i class="fa fa-check"></i><b>7.1</b> FASTA and FASTQ formats</a></li>
<li class="chapter" data-level="7.2" data-path="quality-check-on-sequencing-reads.html"><a href="quality-check-on-sequencing-reads.html"><i class="fa fa-check"></i><b>7.2</b> Quality check on sequencing reads</a><ul>
<li class="chapter" data-level="7.2.1" data-path="quality-check-on-sequencing-reads.html"><a href="quality-check-on-sequencing-reads.html#sequence-quality-per-basecycle"><i class="fa fa-check"></i><b>7.2.1</b> Sequence quality per base/cycle</a></li>
<li class="chapter" data-level="7.2.2" data-path="quality-check-on-sequencing-reads.html"><a href="quality-check-on-sequencing-reads.html#sequence-content-per-basecycle"><i class="fa fa-check"></i><b>7.2.2</b> Sequence content per base/cycle</a></li>
<li class="chapter" data-level="7.2.3" data-path="quality-check-on-sequencing-reads.html"><a href="quality-check-on-sequencing-reads.html#read-frequency-plot"><i class="fa fa-check"></i><b>7.2.3</b> Read frequency plot</a></li>
<li class="chapter" data-level="7.2.4" data-path="quality-check-on-sequencing-reads.html"><a href="quality-check-on-sequencing-reads.html#other-quality-metrics-and-qc-tools"><i class="fa fa-check"></i><b>7.2.4</b> Other quality metrics and QC tools</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="filtering-and-trimming-reads.html"><a href="filtering-and-trimming-reads.html"><i class="fa fa-check"></i><b>7.3</b> Filtering and trimming reads</a></li>
<li class="chapter" data-level="7.4" data-path="mappingaligning-reads-to-the-genome.html"><a href="mappingaligning-reads-to-the-genome.html"><i class="fa fa-check"></i><b>7.4</b> Mapping/aligning reads to the genome</a></li>
<li class="chapter" data-level="7.5" data-path="further-processing-of-aligned-reads.html"><a href="further-processing-of-aligned-reads.html"><i class="fa fa-check"></i><b>7.5</b> Further processing of aligned reads</a></li>
<li class="chapter" data-level="7.6" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>7.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="rnaseqanalysis.html"><a href="rnaseqanalysis.html"><i class="fa fa-check"></i><b>8</b> RNA-seq Analysis</a><ul>
<li class="chapter" data-level="8.1" data-path="what-is-gene-expression.html"><a href="what-is-gene-expression.html"><i class="fa fa-check"></i><b>8.1</b> What is gene expression?</a></li>
<li class="chapter" data-level="8.2" data-path="methods-to-detect-gene-expression.html"><a href="methods-to-detect-gene-expression.html"><i class="fa fa-check"></i><b>8.2</b> Methods to detect gene expression</a></li>
<li class="chapter" data-level="8.3" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><i class="fa fa-check"></i><b>8.3</b> Gene expression analysis using high-throughput sequencing technologies</a><ul>
<li class="chapter" data-level="8.3.1" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#processing-raw-data"><i class="fa fa-check"></i><b>8.3.1</b> Processing raw data</a></li>
<li class="chapter" data-level="8.3.2" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#alignment"><i class="fa fa-check"></i><b>8.3.2</b> Alignment</a></li>
<li class="chapter" data-level="8.3.3" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#quantification"><i class="fa fa-check"></i><b>8.3.3</b> Quantification</a></li>
<li class="chapter" data-level="8.3.4" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#within-sample-normalization-of-the-read-counts"><i class="fa fa-check"></i><b>8.3.4</b> Within sample normalization of the read counts</a></li>
<li class="chapter" data-level="8.3.5" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#computing-different-normalization-schemes-in-r"><i class="fa fa-check"></i><b>8.3.5</b> Computing different normalization schemes in R</a></li>
<li class="chapter" data-level="8.3.6" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#exploratory-analysis-of-the-read-count-table"><i class="fa fa-check"></i><b>8.3.6</b> Exploratory analysis of the read count table</a></li>
<li class="chapter" data-level="8.3.7" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#differential-expression-analysis"><i class="fa fa-check"></i><b>8.3.7</b> Differential expression analysis</a></li>
<li class="chapter" data-level="8.3.8" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#functional-enrichment-analysis"><i class="fa fa-check"></i><b>8.3.8</b> Functional enrichment analysis</a></li>
<li class="chapter" data-level="8.3.9" data-path="gene-expression-analysis-using-high-throughput-sequencing-technologies.html"><a href="gene-expression-analysis-using-high-throughput-sequencing-technologies.html#accounting-for-additional-sources-of-variation"><i class="fa fa-check"></i><b>8.3.9</b> Accounting for additional sources of variation</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="other-applications-of-rna-seq.html"><a href="other-applications-of-rna-seq.html"><i class="fa fa-check"></i><b>8.4</b> Other applications of RNA-seq</a></li>
<li class="chapter" data-level="8.5" data-path="exercises-6.html"><a href="exercises-6.html"><i class="fa fa-check"></i><b>8.5</b> Exercises</a><ul>
<li class="chapter" data-level="8.5.1" data-path="exercises-6.html"><a href="exercises-6.html#exploring-the-count-tables"><i class="fa fa-check"></i><b>8.5.1</b> Exploring the count tables</a></li>
<li class="chapter" data-level="8.5.2" data-path="exercises-6.html"><a href="exercises-6.html#differential-expression-analysis-1"><i class="fa fa-check"></i><b>8.5.2</b> Differential expression analysis</a></li>
<li class="chapter" data-level="8.5.3" data-path="exercises-6.html"><a href="exercises-6.html#functional-enrichment-analysis-1"><i class="fa fa-check"></i><b>8.5.3</b> Functional enrichment analysis</a></li>
<li class="chapter" data-level="8.5.4" data-path="exercises-6.html"><a href="exercises-6.html#removing-unwanted-variation-from-the-expression-data"><i class="fa fa-check"></i><b>8.5.4</b> Removing unwanted variation from the expression data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chipseq.html"><a href="chipseq.html"><i class="fa fa-check"></i><b>9</b> ChIP-seq analysis</a><ul>
<li class="chapter" data-level="9.1" data-path="regulatory-protein-dna-interactions.html"><a href="regulatory-protein-dna-interactions.html"><i class="fa fa-check"></i><b>9.1</b> Regulatory protein-DNA interactions</a></li>
<li class="chapter" data-level="9.2" data-path="measuring-protein-dna-interactions-with-chip-seq.html"><a href="measuring-protein-dna-interactions-with-chip-seq.html"><i class="fa fa-check"></i><b>9.2</b> Measuring protein-DNA interactions with ChIP-seq</a></li>
<li class="chapter" data-level="9.3" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><i class="fa fa-check"></i><b>9.3</b> Factors that affect ChIP-seq experiment and analysis quality</a><ul>
<li class="chapter" data-level="9.3.1" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#antibody-specificity"><i class="fa fa-check"></i><b>9.3.1</b> Antibody specificity</a></li>
<li class="chapter" data-level="9.3.2" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#sequencing-depth"><i class="fa fa-check"></i><b>9.3.2</b> Sequencing depth</a></li>
<li class="chapter" data-level="9.3.3" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#pcr-duplication"><i class="fa fa-check"></i><b>9.3.3</b> PCR duplication</a></li>
<li class="chapter" data-level="9.3.4" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#biological-replicates"><i class="fa fa-check"></i><b>9.3.4</b> Biological replicates</a></li>
<li class="chapter" data-level="9.3.5" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#control-experiments"><i class="fa fa-check"></i><b>9.3.5</b> Control experiments</a></li>
<li class="chapter" data-level="9.3.6" data-path="factors-that-affect-chip-seq-experiment-and-analysis-quality.html"><a href="factors-that-affect-chip-seq-experiment-and-analysis-quality.html#using-tagged-proteins"><i class="fa fa-check"></i><b>9.3.6</b> Using tagged proteins</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="pre-processing-chip-data.html"><a href="pre-processing-chip-data.html"><i class="fa fa-check"></i><b>9.4</b> Pre-processing ChIP data</a><ul>
<li class="chapter" data-level="9.4.1" data-path="pre-processing-chip-data.html"><a href="pre-processing-chip-data.html#mapping-of-chip-seq-data"><i class="fa fa-check"></i><b>9.4.1</b> Mapping of ChIP-seq data</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="chip-quality-control.html"><a href="chip-quality-control.html"><i class="fa fa-check"></i><b>9.5</b> ChIP quality control</a><ul>
<li class="chapter" data-level="9.5.1" data-path="chip-quality-control.html"><a href="chip-quality-control.html#the-data"><i class="fa fa-check"></i><b>9.5.1</b> The data</a></li>
<li class="chapter" data-level="9.5.2" data-path="chip-quality-control.html"><a href="chip-quality-control.html#sample-clustering"><i class="fa fa-check"></i><b>9.5.2</b> Sample clustering</a></li>
<li class="chapter" data-level="9.5.3" data-path="chip-quality-control.html"><a href="chip-quality-control.html#visualization-in-the-genome-browser"><i class="fa fa-check"></i><b>9.5.3</b> Visualization in the genome browser</a></li>
<li class="chapter" data-level="9.5.4" data-path="chip-quality-control.html"><a href="chip-quality-control.html#plus-and-minus-strand-cross-correlation"><i class="fa fa-check"></i><b>9.5.4</b> Plus and minus strand cross-correlation</a></li>
<li class="chapter" data-level="9.5.5" data-path="chip-quality-control.html"><a href="chip-quality-control.html#gc-bias-quantification"><i class="fa fa-check"></i><b>9.5.5</b> GC bias quantification</a></li>
<li class="chapter" data-level="9.5.6" data-path="chip-quality-control.html"><a href="chip-quality-control.html#sequence-read-genomic-distribution"><i class="fa fa-check"></i><b>9.5.6</b> Sequence read genomic distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="peak-calling.html"><a href="peak-calling.html"><i class="fa fa-check"></i><b>9.6</b> Peak calling</a><ul>
<li class="chapter" data-level="9.6.1" data-path="peak-calling.html"><a href="peak-calling.html#types-of-chip-seq-experiments"><i class="fa fa-check"></i><b>9.6.1</b> Types of ChIP-seq experiments</a></li>
<li class="chapter" data-level="9.6.2" data-path="peak-calling.html"><a href="peak-calling.html#peak-calling-sharp-peaks"><i class="fa fa-check"></i><b>9.6.2</b> Peak calling: Sharp peaks</a></li>
<li class="chapter" data-level="9.6.3" data-path="peak-calling.html"><a href="peak-calling.html#peak-calling-broad-regions"><i class="fa fa-check"></i><b>9.6.3</b> Peak calling: Broad regions</a></li>
<li class="chapter" data-level="9.6.4" data-path="peak-calling.html"><a href="peak-calling.html#peak-quality-control"><i class="fa fa-check"></i><b>9.6.4</b> Peak quality control</a></li>
<li class="chapter" data-level="9.6.5" data-path="peak-calling.html"><a href="peak-calling.html#peak-annotation"><i class="fa fa-check"></i><b>9.6.5</b> Peak annotation</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="motif-discovery.html"><a href="motif-discovery.html"><i class="fa fa-check"></i><b>9.7</b> Motif discovery</a><ul>
<li class="chapter" data-level="9.7.1" data-path="motif-discovery.html"><a href="motif-discovery.html#motif-comparison"><i class="fa fa-check"></i><b>9.7.1</b> Motif comparison</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="what-to-do-next.html"><a href="what-to-do-next.html"><i class="fa fa-check"></i><b>9.8</b> What to do next?</a></li>
<li class="chapter" data-level="9.9" data-path="exercises-7.html"><a href="exercises-7.html"><i class="fa fa-check"></i><b>9.9</b> Exercises</a><ul>
<li class="chapter" data-level="9.9.1" data-path="exercises-7.html"><a href="exercises-7.html#quality-control"><i class="fa fa-check"></i><b>9.9.1</b> Quality control</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bsseq.html"><a href="bsseq.html"><i class="fa fa-check"></i><b>10</b> DNA methylation analysis using bisulfite sequencing data</a><ul>
<li class="chapter" data-level="10.1" data-path="what-is-dna-methylation.html"><a href="what-is-dna-methylation.html"><i class="fa fa-check"></i><b>10.1</b> What is DNA methylation ?</a><ul>
<li class="chapter" data-level="10.1.1" data-path="what-is-dna-methylation.html"><a href="what-is-dna-methylation.html#how-dna-methylation-is-set"><i class="fa fa-check"></i><b>10.1.1</b> How DNA methylation is set ?</a></li>
<li class="chapter" data-level="10.1.2" data-path="what-is-dna-methylation.html"><a href="what-is-dna-methylation.html#how-to-measure-dna-methylation-with-bisulfite-sequencing"><i class="fa fa-check"></i><b>10.1.2</b> How to measure DNA methylation with bisulfite sequencing</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="analyzing-dna-methylation-data.html"><a href="analyzing-dna-methylation-data.html"><i class="fa fa-check"></i><b>10.2</b> Analyzing DNA methylation data</a></li>
<li class="chapter" data-level="10.3" data-path="processing-raw-data-and-getting-data-into-r.html"><a href="processing-raw-data-and-getting-data-into-r.html"><i class="fa fa-check"></i><b>10.3</b> Processing raw data and getting data into R</a></li>
<li class="chapter" data-level="10.4" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html"><i class="fa fa-check"></i><b>10.4</b> Data filtering and exploratory analysis</a><ul>
<li class="chapter" data-level="10.4.1" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#reading-methylation-call-files"><i class="fa fa-check"></i><b>10.4.1</b> Reading methylation call files</a></li>
<li class="chapter" data-level="10.4.2" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#further-quality-check"><i class="fa fa-check"></i><b>10.4.2</b> Further quality check</a></li>
<li class="chapter" data-level="10.4.3" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#merging-samples-into-a-single-table"><i class="fa fa-check"></i><b>10.4.3</b> Merging samples into a single table</a></li>
<li class="chapter" data-level="10.4.4" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#filtering-cpgs"><i class="fa fa-check"></i><b>10.4.4</b> Filtering CpGs</a></li>
<li class="chapter" data-level="10.4.5" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#clustering-samples"><i class="fa fa-check"></i><b>10.4.5</b> Clustering samples</a></li>
<li class="chapter" data-level="10.4.6" data-path="data-filtering-and-exploratory-analysis.html"><a href="data-filtering-and-exploratory-analysis.html#principal-component-analysis-1"><i class="fa fa-check"></i><b>10.4.6</b> Principal component analysis</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="extracting-interesting-regions-differential-methylation-and-segmentation.html"><a href="extracting-interesting-regions-differential-methylation-and-segmentation.html"><i class="fa fa-check"></i><b>10.5</b> Extracting interesting regions: Differential methylation and segmentation</a><ul>
<li class="chapter" data-level="10.5.1" data-path="extracting-interesting-regions-differential-methylation-and-segmentation.html"><a href="extracting-interesting-regions-differential-methylation-and-segmentation.html#differential-methylation"><i class="fa fa-check"></i><b>10.5.1</b> Differential methylation</a></li>
<li class="chapter" data-level="10.5.2" data-path="extracting-interesting-regions-differential-methylation-and-segmentation.html"><a href="extracting-interesting-regions-differential-methylation-and-segmentation.html#methylation-segmentation"><i class="fa fa-check"></i><b>10.5.2</b> Methylation segmentation</a></li>
<li class="chapter" data-level="10.5.3" data-path="extracting-interesting-regions-differential-methylation-and-segmentation.html"><a href="extracting-interesting-regions-differential-methylation-and-segmentation.html#working-with-large-files"><i class="fa fa-check"></i><b>10.5.3</b> Working with large files</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="annotation-of-dmrsdmcs-and-segments.html"><a href="annotation-of-dmrsdmcs-and-segments.html"><i class="fa fa-check"></i><b>10.6</b> Annotation of DMRs/DMCs and segments</a><ul>
<li class="chapter" data-level="10.6.1" data-path="annotation-of-dmrsdmcs-and-segments.html"><a href="annotation-of-dmrsdmcs-and-segments.html#further-annotation-with-genes-or-gene-sets"><i class="fa fa-check"></i><b>10.6.1</b> Further annotation with genes or gene sets</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="other-r-packages-that-can-be-used-for-methylation-analysis.html"><a href="other-r-packages-that-can-be-used-for-methylation-analysis.html"><i class="fa fa-check"></i><b>10.7</b> Other R packages that can be used for methylation analysis</a></li>
<li class="chapter" data-level="10.8" data-path="exercises-8.html"><a href="exercises-8.html"><i class="fa fa-check"></i><b>10.8</b> Exercises</a><ul>
<li class="chapter" data-level="10.8.1" data-path="exercises-8.html"><a href="exercises-8.html#differential-methylation-1"><i class="fa fa-check"></i><b>10.8.1</b> Differential methylation</a></li>
<li class="chapter" data-level="10.8.2" data-path="exercises-8.html"><a href="exercises-8.html#methylome-segmentation"><i class="fa fa-check"></i><b>10.8.2</b> Methylome segmentation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="multiomics.html"><a href="multiomics.html"><i class="fa fa-check"></i><b>11</b> Multi-omics Analysis</a><ul>
<li class="chapter" data-level="11.1" data-path="use-case-multi-omics-data-from-colorectal-cancer.html"><a href="use-case-multi-omics-data-from-colorectal-cancer.html"><i class="fa fa-check"></i><b>11.1</b> Use case: Multi-omics data from colorectal cancer</a></li>
<li class="chapter" data-level="11.2" data-path="latent-variable-models-for-multi-omics-integration.html"><a href="latent-variable-models-for-multi-omics-integration.html"><i class="fa fa-check"></i><b>11.2</b> Latent variable models for multi-omics integration</a></li>
<li class="chapter" data-level="11.3" data-path="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html"><a href="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html"><i class="fa fa-check"></i><b>11.3</b> Matrix factorization methods for unsupervised multi-omics data integration</a><ul>
<li class="chapter" data-level="11.3.1" data-path="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html"><a href="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html#multiple-factor-analysis"><i class="fa fa-check"></i><b>11.3.1</b> Multiple factor analysis</a></li>
<li class="chapter" data-level="11.3.2" data-path="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html"><a href="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html#joint-non-negative-matrix-factorization"><i class="fa fa-check"></i><b>11.3.2</b> Joint non-negative matrix Factorization</a></li>
<li class="chapter" data-level="11.3.3" data-path="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html"><a href="matrix-factorization-methods-for-unsupervised-multi-omics-data-integration.html#icluster"><i class="fa fa-check"></i><b>11.3.3</b> iCluster</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="clustering-using-latent-factors.html"><a href="clustering-using-latent-factors.html"><i class="fa fa-check"></i><b>11.4</b> Clustering using latent factors</a><ul>
<li class="chapter" data-level="11.4.1" data-path="clustering-using-latent-factors.html"><a href="clustering-using-latent-factors.html#one-hot-clustering"><i class="fa fa-check"></i><b>11.4.1</b> One-hot clustering</a></li>
<li class="chapter" data-level="11.4.2" data-path="clustering-using-latent-factors.html"><a href="clustering-using-latent-factors.html#k-means-clustering-1"><i class="fa fa-check"></i><b>11.4.2</b> K-means clustering</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="biological-interpretation-of-latent-factors.html"><a href="biological-interpretation-of-latent-factors.html"><i class="fa fa-check"></i><b>11.5</b> Biological interpretation of latent factors</a><ul>
<li class="chapter" data-level="11.5.1" data-path="biological-interpretation-of-latent-factors.html"><a href="biological-interpretation-of-latent-factors.html#inspection-of-feature-weights-in-loading-vectors"><i class="fa fa-check"></i><b>11.5.1</b> Inspection of feature weights in loading vectors</a></li>
<li class="chapter" data-level="11.5.2" data-path="biological-interpretation-of-latent-factors.html"><a href="biological-interpretation-of-latent-factors.html#making-sense-of-factors-using-enrichment-analysis"><i class="fa fa-check"></i><b>11.5.2</b> Making sense of factors using enrichment analysis</a></li>
<li class="chapter" data-level="11.5.3" data-path="biological-interpretation-of-latent-factors.html"><a href="biological-interpretation-of-latent-factors.html#interpretation-using-additional-covariates"><i class="fa fa-check"></i><b>11.5.3</b> Interpretation using additional covariates</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="exercises-9.html"><a href="exercises-9.html"><i class="fa fa-check"></i><b>11.6</b> Exercises</a><ul>
<li class="chapter" data-level="11.6.1" data-path="exercises-9.html"><a href="exercises-9.html#matrix-factorization-methods"><i class="fa fa-check"></i><b>11.6.1</b> Matrix factorization methods</a></li>
<li class="chapter" data-level="11.6.2" data-path="exercises-9.html"><a href="exercises-9.html#clustering-using-latent-factors-1"><i class="fa fa-check"></i><b>11.6.2</b> Clustering using latent factors</a></li>
<li class="chapter" data-level="11.6.3" data-path="exercises-9.html"><a href="exercises-9.html#biological-interpretation-of-latent-factors-1"><i class="fa fa-check"></i><b>11.6.3</b> Biological interpretation of latent factors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Genomics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="relationship-between-variables-linear-models-and-correlation" class="section level2">
<h2><span class="header-section-number">3.3</span> Relationship between variables: Linear models and correlation</h2>
<p>In genomics, we would often need to measure or model the relationship between
variables. We might want to know about expression of a particular gene in liver
in relation to the dosage of a drug that patient receives. Or, we may want to know
DNA methylation of a certain locus in the genome in relation to the age of the sample donor. Or, we might be interested in the relationship between histone
modifications and gene expression. Is there a linear relationship, the more 
histone modification the more the gene is expressed ?</p>
<p>In these
situations and many more, linear regression or linear models can be used to 
model the relationship with a “dependent” or “response” variable (expression or
methylation
in the above examples) and one or more “independent” or “explanatory” variables (age, drug dosage or histone modification in the above examples). Our simple linear model has the
following components.</p>
<p><span class="math display">\[  Y= \beta_0+\beta_1X + \epsilon \]</span></p>
<p>In the equation above, <span class="math inline">\(Y\)</span> is the response variable and <span class="math inline">\(X\)</span> is the explanatory
variable. <span class="math inline">\(\epsilon\)</span> is the mean-zero error term. Since the line fit will not
be able to precisely predict the <span class="math inline">\(Y\)</span> values, there will be some error associated
with each prediction when we compare it to the original <span class="math inline">\(Y\)</span> values. This error
is captured in the <span class="math inline">\(\epsilon\)</span> term. We can alternatively write the model as
follows to emphasize that the model approximates <span class="math inline">\(Y\)</span>, in this case notice that we removed the <span class="math inline">\(\epsilon\)</span> term: <span class="math inline">\(Y \sim \beta_0+\beta_1X\)</span>.</p>
<p>The plot below in Figure <a href="relationship-between-variables-linear-models-and-correlation.html#fig:histoneLmChp3">3.12</a> shows the relationship between
histone modification (trimethylated forms of histone H3 at lysine 4, aka H3K4me3)
and gene expression for 100 genes. The blue line is our model with estimated
coefficients (<span class="math inline">\(\hat{y}=\hat{\beta}_0 + \hat{\beta}_1X\)</span>, where <span class="math inline">\(\hat{\beta}_0\)</span>
and <span class="math inline">\(\hat{\beta}_1\)</span> are the estimated values of <span class="math inline">\(\beta_0\)</span> and
<span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\hat{y}\)</span> indicates the prediction). The red lines indicate the individual
errors per data point, indicated as <span class="math inline">\(\epsilon\)</span> in the formula above.</p>
<div class="figure" style="text-align: center"><span id="fig:histoneLmChp3"></span>
<img src="03-statsForGenomics_files/figure-html/histoneLmChp3-1.png" alt="Relationship between histone modification score and gene expression. Increasing histone modification, H3K4me3, seems to be associated with increasing gene expression. Each dot is a gene" width="60%" />
<p class="caption">
FIGURE 3.12: Relationship between histone modification score and gene expression. Increasing histone modification, H3K4me3, seems to be associated with increasing gene expression. Each dot is a gene
</p>
</div>
<p>There could be more than one explanatory variable. We then simply add more <span class="math inline">\(X\)</span>
and <span class="math inline">\(\beta\)</span> to our model. If there are two explanatory variables our model
will look like this:</p>
<p><span class="math display">\[  Y= \beta_0+\beta_1X_1 +\beta_2X_2 + \epsilon \]</span></p>
<p>In this case, we will be fitting a plane rather than a line. However, the fitting
process which we will describe in the later sections will not change for our
gene expression problem. We can introduce one more histone modification, H3K27me3. We will then have a linear model with 2 explanatory variables and the
fitted plane will look like the one in Figure <a href="relationship-between-variables-linear-models-and-correlation.html#fig:histoneLm2chp3">3.13</a>. The gene expression values are shown
as dots below and above the fitted plane. Linear regression and its extensions which makes use of other distributions (generalized linear models)  are central in computational genomics for statistical tests. We will see more of how regression is used in statistical hypothesis testing for computational genomics in Chapters <a href="rnaseqanalysis.html#rnaseqanalysis">8</a> and <a href="bsseq.html#bsseq">10</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:histoneLm2chp3"></span>
<img src="03-statsForGenomics_files/figure-html/histoneLm2chp3-1.png" alt="Association of Gene expression with H3K4me3 and H27Kme3 histone modifications." width="65%" />
<p class="caption">
FIGURE 3.13: Association of Gene expression with H3K4me3 and H27Kme3 histone modifications.
</p>
</div>
<div id="matrix-notation-for-linear-models" class="section level4">
<h4><span class="header-section-number">3.3.0.1</span> Matrix notation for linear models</h4>
<p>We can naturally have more explanatory variables than just two. The formula
below has <span class="math inline">\(n\)</span> explanatory variables.</p>
<p><span class="math display">\[Y= \beta_0+\beta_1X_1+\beta_2X_2 +  \beta_3X_3 + .. + \beta_nX_n +\epsilon\]</span></p>
<p>If there are many variables, it would be easier
to write the model in matrix notation. The matrix form of linear model with
two explanatory variables will look like the one
below. The first matrix would be our data matrix. This contains our explanatory
variables and a column of 1s. The second term is a column vector of <span class="math inline">\(\beta\)</span>
values. We also add a vector of error terms, <span class="math inline">\(\epsilon\)</span>s, to the matrix multiplication.</p>
<p><span class="math display">\[
 \mathbf{Y} = \left[\begin{array}{rrr}
1 &amp; X_{1,1} &amp; X_{1,2} \\
1 &amp; X_{2,1} &amp; X_{2,2} \\
1 &amp; X_{3,1} &amp; X_{3,2} \\
1 &amp; X_{4,1} &amp; X_{4,2}
\end{array}\right]
%
\left[\begin{array}{rrr}
\beta_0 \\
\beta_1 \\
\beta_2 
\end{array}\right]
% 
+
\left[\begin{array}{rrr}
\epsilon_1 \\
\epsilon_2 \\ 
\epsilon_3 \\ 
\epsilon_0
\end{array}\right]
\]</span></p>
<p>The multiplication of the data matrix and <span class="math inline">\(\beta\)</span> vector and addition of the
error terms simply results in the the following set of equations per data point:</p>
<p><span class="math display">\[
\begin{aligned}
Y_1= \beta_0+\beta_1X_{1,1}+\beta_2X_{1,2} +\epsilon_1 \\
Y_2= \beta_0+\beta_1X_{2,1}+\beta_2X_{2,2} +\epsilon_2 \\
Y_3= \beta_0+\beta_1X_{3,1}+\beta_2X_{3,2} +\epsilon_3 \\
Y_4= \beta_0+\beta_1X_{4,1}+\beta_2X_{4,2} +\epsilon_4 
\end{aligned}
\]</span></p>
<p>This expression involving the multiplication of the data matrix, the
<span class="math inline">\(\beta\)</span> vector and vector of error terms (<span class="math inline">\(\epsilon\)</span>)
could be simply written as follows.</p>
<p><span class="math display">\[Y=X\beta + \epsilon\]</span></p>
<p>In the equatin, above <span class="math inline">\(Y\)</span> is the vector of response variables, <span class="math inline">\(X\)</span> is the
data matrix, and <span class="math inline">\(\beta\)</span> is the vector of coefficients.
This notation is more concise and often used in scientific papers. However, this
also means you need some understanding of linear algebra to follow the math
laid out in such resources.</p>
</div>
<div id="how-to-fit-a-line" class="section level3">
<h3><span class="header-section-number">3.3.1</span> How to fit a line</h3>
<p>At this point a major question is left unanswered: How did we fit this line?
We basically need to define <span class="math inline">\(\beta\)</span> values in a structured way.
There are multiple ways of understanding how
to do this, all of which converge to the same
end point. We will describe them one by one.</p>
<div id="the-cost-or-loss-function-approach" class="section level4">
<h4><span class="header-section-number">3.3.1.1</span> The cost or loss function approach</h4>
<p>This is the first approach and in my opinion is easiest to understand. 
We try to optimize a function, often called the “cost function” or “loss function”. 
The cost function
is the sum of squared differences between the predicted <span class="math inline">\(\hat{Y}\)</span> values from our model
and the original <span class="math inline">\(Y\)</span> values. The optimization procedure tries to find <span class="math inline">\(\beta\)</span> values 
that minimize this difference between the reality and predicted values.</p>
<p><span class="math display">\[min \sum{(y_i-(\beta_0+\beta_1x_i))^2}\]</span></p>
<p>Note that this is related to the error term, <span class="math inline">\(\epsilon\)</span>, we already mentioned
above. We are trying to minimize the squared sum of <span class="math inline">\(\epsilon_i\)</span> for each data
point. We can do this minimization by a bit of calculus.
The rough algorithm is as follows:</p>
<ol style="list-style-type: decimal">
<li>Pick a random starting point, random <span class="math inline">\(\beta\)</span> values.</li>
<li>Take the partial derivatives of the cost function to see which direction is
the way to go in the cost function.</li>
<li>Take a step toward the direction that minimizes the cost function.
<ul>
<li>Step size is a parameter to choose, there are many variants.</li>
</ul></li>
<li>repeat step 2,3 until convergence.</li>
</ol>
<p>This is the basis of the “gradient descent” algorithm. With the help of partial
derivatives we define a “gradient” on the cost function and follow that through
multiple iterations until convergence, meaning until the results do not
improve defined by a margin. The algorithm usually converges to optimum <span class="math inline">\(\beta\)</span>
values. In Figure <a href="relationship-between-variables-linear-models-and-correlation.html#fig:3dcostfunc">3.14</a>, we show the cost function over various <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>
values for the histone modification and gene expression data set. The algorithm
will pick a point on this graph and traverse it incrementally based on the
derivatives and converge to the bottom of the cost function “well”. Such optimization methods are the core of machine learning methods we will cover later in Chapters <a href="unsupervisedLearning.html#unsupervisedLearning">4</a> and
<a href="supervisedLearning.html#supervisedLearning">5</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:3dcostfunc"></span>
<img src="03-statsForGenomics_files/figure-html/3dcostfunc-1.png" alt="Cost function landscape for linear regression with changing beta values. The optimization process tries to find the lowest point in this landscape by implementing a strategy for updating beta values toward the lowest point in the landscape." width="55%" />
<p class="caption">
FIGURE 3.14: Cost function landscape for linear regression with changing beta values. The optimization process tries to find the lowest point in this landscape by implementing a strategy for updating beta values toward the lowest point in the landscape.
</p>
</div>
</div>
<div id="not-cost-function-but-maximum-likelihood-function" class="section level4">
<h4><span class="header-section-number">3.3.1.2</span> Not cost function but maximum likelihood function</h4>
<p>We can also think of this problem from a more statistical point of view. In 
essence, we are looking for best statistical parameters, in this
case <span class="math inline">\(\beta\)</span> values, for our model that are most likely to produce such a
scatter of data points given the explanatory variables.This is called the
“maximum likelihood” approach. The approach assumes that a given response variable <span class="math inline">\(y_i\)</span> follows a normal distribution with mean <span class="math inline">\(\beta_0+\beta_1x_i\)</span> and  variance <span class="math inline">\(s^2\)</span>. Therefore the probability of observing any given <span class="math inline">\(y_i\)</span> value is dependent on the <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> values. Since <span class="math inline">\(x_i\)</span>, the explanatory variable, is fixed within our data set, we can maximize the probability of observing any given <span class="math inline">\(y_i\)</span> by varying <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> values. The trick is to find <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> values that maximizes the probability of observing all the response variables in the dataset given the explanatory variables. The probability of observing a response variable <span class="math inline">\(y_i\)</span> with assumptions we described above is shown below. Note that this assumes variance is constant and <span class="math inline">\(s^2=\frac{\sum{\epsilon_i}}{n-2}\)</span> is an unbiased estimation for population variance, <span class="math inline">\(\sigma^2\)</span>.</p>
<p><span class="math display">\[P(y_{i})=\frac{1}{s\sqrt{2\pi} }e^{-\frac{1}{2}\left(\frac{y_i-(\beta_0 + \beta_1x_i)}{s}\right)^2}\]</span></p>
<p>Following from the probability equation above, the likelihood function (shown as <span class="math inline">\(L\)</span> below) for
linear regression is  multiplication of <span class="math inline">\(P(y_{i})\)</span> for all data points.</p>
<p><span class="math display">\[L=P(y_1)P(y_2)P(y_3)..P(y_n)=\prod\limits_{i=1}^n{P_i}\]</span></p>
<p>This can be simplified to the following equation by some algebra, assumption of normal distribution, and taking logs (since it is
easier to add than multiply).</p>
<p><span class="math display">\[ln(L) = -nln(s\sqrt{2\pi}) - \frac{1}{2s^2} \sum\limits_{i=1}^n{(y_i-(\beta_0 + \beta_1x_i))^2} \]</span></p>
<p>As you can see, the right part of the function is the negative of the cost function
defined above. If we wanted to optimize this function we would need to take the derivative of
the function with respect to the <span class="math inline">\(\beta\)</span> parameters. That means we can ignore the
first part since there are no <span class="math inline">\(\beta\)</span> terms there. This simply reduces to the
negative of the cost function. Hence, this approach produces exactly the same
result as the cost function approach. The difference is that we defined our
problem
within the domain of statistics. This particular function has still to be optimized. This can be done with some calculus without the need for an
iterative approach.</p>
<p>The maximum likelihood approach also opens up other possibilities for regression. For the case, above we assumed that the points around the mean are distributed by normal distribution. However, there are other cases where this assumption may not hold. For example, for the count data the mean and variance relationship is not constant; the higher the mean counts, the higher the variance. In these cases, the regression framework with maximum likelihood estimation can still be used. We simply change the underlying assumptions about the distribution and calculate the likelihood with a new distribution in mind,
and maximize the parameters for that likelihood. This gives way to “generalized linear model” approach where errors for the response variables can have other distributions than normal distribution. We will see examples of these generalized linear models in Chapter <a href="rnaseqanalysis.html#rnaseqanalysis">8</a> and <a href="bsseq.html#bsseq">10</a>.</p>
</div>
<div id="linear-algebra-and-closed-form-solution-to-linear-regression" class="section level4">
<h4><span class="header-section-number">3.3.1.3</span> Linear algebra and closed-form solution to linear regression</h4>
<p>The last approach we will describe is the minimization process using linear 
algebra. If you find this concept challenging, feel free to skip it, but scientific publications and other books frequently use matrix notation and linear algebra to define and solve regression problems. In this case, we do not use an iterative approach. Instead, we will
minimize the cost function by explicitly taking its derivatives with respect to
<span class="math inline">\(\beta\)</span>’s and setting them to zero. This is doable by employing linear algebra
and matrix calculus. This approach is also called “ordinary least squares”. We 
will not
show the whole derivation here, but the following expression
is what we are trying to minimize in matrix notation, which is basically a
different notation of the same minimization problem defined above. Remember
<span class="math inline">\(\epsilon_i=Y_i-(\beta_0+\beta_1x_i)\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\sum\epsilon_{i}^2=\epsilon^T\epsilon=(Y-{\beta}{X})^T(Y-{\beta}{X}) \\
=Y^T{Y}-2{\beta}^T{Y}+{\beta}^TX^TX{\beta}
\end{aligned}
\]</span>
After rearranging the terms, we take the derivative of <span class="math inline">\(\epsilon^T\epsilon\)</span>
with respect to <span class="math inline">\(\beta\)</span>, and equalize that to zero. We then arrive at
the following for estimated <span class="math inline">\(\beta\)</span> values, <span class="math inline">\(\hat{\beta}\)</span>:</p>
<p><span class="math display">\[\hat{\beta}=(X^TX)^{-1}X^TY\]</span></p>
<p>This requires you to calculate the inverse of the <span class="math inline">\(X^TX\)</span> term, which could
be slow for large matrices. Using an iterative approach over the cost function
derivatives will be faster for larger problems.
The linear algebra notation is something you will see in the papers
or other resources often. If you input the data matrix X and solve the <span class="math inline">\((X^TX)^{-1}\)</span>
,
you get the following values for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> for simple regression . However, we should note that this simple linear regression case can easily
be solved algebraically without the need for matrix operations. This can be done
by taking the derivative of <span class="math inline">\(\sum{(y_i-(\beta_0+\beta_1x_i))^2}\)</span> with respect to
<span class="math inline">\(\beta_1\)</span>, rearranging the terms and equalizing the derivative to zero.</p>
<p><span class="math display">\[\hat{\beta_1}=\frac{\sum{(x_i-\overline{X})(y_i-\overline{Y})}}{ \sum{(x_i-\overline{X})^2} }\]</span>
<span class="math display">\[\hat{\beta_0}=\overline{Y}-\hat{\beta_1}\overline{X}\]</span></p>
</div>
<div id="fitting-lines-in-r" class="section level4">
<h4><span class="header-section-number">3.3.1.4</span> Fitting lines in R</h4>
<p>After all this theory, you will be surprised how easy it is to fit lines in R.
This is achieved just by the <code>lm()</code> function, which stands for linear models. Let’s do this
for a simulated data set and plot the fit. The first step is to simulate the
data. We will decide on <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> values. Then we will decide
on the variance parameter, <span class="math inline">\(\sigma\)</span> to be used in simulation of error terms,
<span class="math inline">\(\epsilon\)</span>. We will first find <span class="math inline">\(Y\)</span> values, just using the linear equation
<span class="math inline">\(Y=\beta0+\beta_1X\)</span>, for
a set of <span class="math inline">\(X\)</span> values. Then, we will add the error terms to get our simulated values.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-1"></a><span class="co"># set random number seed, so that the random numbers from the text</span></span>
<span id="cb172-2"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-2"></a><span class="co"># is the same when you run the code.</span></span>
<span id="cb172-3"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-3"></a><span class="kw">set.seed</span>(<span class="dv">32</span>)</span>
<span id="cb172-4"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-4"></a></span>
<span id="cb172-5"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-5"></a><span class="co"># get 50 X values between 1 and 100</span></span>
<span id="cb172-6"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-6"></a>x =<span class="st"> </span><span class="kw">runif</span>(<span class="dv">50</span>,<span class="dv">1</span>,<span class="dv">100</span>)</span>
<span id="cb172-7"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-7"></a></span>
<span id="cb172-8"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-8"></a><span class="co"># set b0,b1 and varience (sigma)</span></span>
<span id="cb172-9"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-9"></a>b0 =<span class="st"> </span><span class="dv">10</span></span>
<span id="cb172-10"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-10"></a>b1 =<span class="st"> </span><span class="dv">2</span></span>
<span id="cb172-11"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-11"></a>sigma =<span class="st"> </span><span class="dv">20</span></span>
<span id="cb172-12"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-12"></a><span class="co"># simulate error terms from normal distribution</span></span>
<span id="cb172-13"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-13"></a>eps =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">50</span>,<span class="dv">0</span>,sigma)</span>
<span id="cb172-14"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-14"></a><span class="co"># get y values from the linear equation and addition of error terms</span></span>
<span id="cb172-15"><a href="relationship-between-variables-linear-models-and-correlation.html#cb172-15"></a>y =<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x<span class="op">+</span><span class="st"> </span>eps</span></code></pre></div>
<p>Now let us fit a line using the <code>lm()</code> function. The function requires a formula, and
optionally a data frame. We need to pass the following expression within the
<code>lm()</code> function, <code>y~x</code>, where <code>y</code> is the simulated <span class="math inline">\(Y\)</span> values and <code>x</code> is the explanatory variables <span class="math inline">\(X\)</span>. We will then use the <code>abline()</code> function to draw the fit. The resulting plot is shown in Figure <a href="relationship-between-variables-linear-models-and-correlation.html#fig:geneExpLinearModel">3.15</a>.</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="relationship-between-variables-linear-models-and-correlation.html#cb173-1"></a>mod1=<span class="kw">lm</span>(y<span class="op">~</span>x)</span>
<span id="cb173-2"><a href="relationship-between-variables-linear-models-and-correlation.html#cb173-2"></a></span>
<span id="cb173-3"><a href="relationship-between-variables-linear-models-and-correlation.html#cb173-3"></a><span class="co"># plot the data points</span></span>
<span id="cb173-4"><a href="relationship-between-variables-linear-models-and-correlation.html#cb173-4"></a><span class="kw">plot</span>(x,y,<span class="dt">pch=</span><span class="dv">20</span>,</span>
<span id="cb173-5"><a href="relationship-between-variables-linear-models-and-correlation.html#cb173-5"></a>     <span class="dt">ylab=</span><span class="st">&quot;Gene Expression&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Histone modification score&quot;</span>)</span>
<span id="cb173-6"><a href="relationship-between-variables-linear-models-and-correlation.html#cb173-6"></a><span class="co"># plot the linear fit</span></span>
<span id="cb173-7"><a href="relationship-between-variables-linear-models-and-correlation.html#cb173-7"></a><span class="kw">abline</span>(mod1,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:geneExpLinearModel"></span>
<img src="03-statsForGenomics_files/figure-html/geneExpLinearModel-1.png" alt="Gene expression and histone modification score modeled by linear regression." width="60%" />
<p class="caption">
FIGURE 3.15: Gene expression and histone modification score modeled by linear regression.
</p>
</div>
</div>
</div>
<div id="how-to-estimate-the-error-of-the-coefficients" class="section level3">
<h3><span class="header-section-number">3.3.2</span> How to estimate the error of the coefficients</h3>
<p>Since we are using a sample to estimate the coefficients, they are
not exact; with every random sample they will vary. In Figure <a href="relationship-between-variables-linear-models-and-correlation.html#fig:regCoeffRandomSamples">3.16</a>, we
take multiple samples from the population and fit lines to each
sample; with each sample the lines slightly change. We are overlaying the
points and the lines for each sample on top of the other samples. When we take 200 samples and fit lines for each of them, the line fits are
variable. And,
we get a normal-like distribution of <span class="math inline">\(\beta\)</span> values with a defined mean 
and standard deviation, which is called standard error of the
coefficients.</p>
<div class="figure" style="text-align: center"><span id="fig:regCoeffRandomSamples"></span>
<img src="03-statsForGenomics_files/figure-html/regCoeffRandomSamples-1.png" alt="Regression coefficients vary with every random sample. The figure illustrates the variability of regression coefficients when regression is done using a sample of data points. Histograms depict this variability for $b_0$ and $b_1$ coefficients." width="55%" />
<p class="caption">
FIGURE 3.16: Regression coefficients vary with every random sample. The figure illustrates the variability of regression coefficients when regression is done using a sample of data points. Histograms depict this variability for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> coefficients.
</p>
</div>
<p>Normally, we will not have access to the population to do repeated sampling,
model fitting, and estimation of the standard error for the coefficients. But
there is statistical theory that helps us infer the population properties from
the sample. When we assume that error terms have constant variance and mean zero
, we can model the uncertainty in the regression coefficients, <span class="math inline">\(\beta\)</span>s.
The estimates for standard errors of <span class="math inline">\(\beta\)</span>s for simple regression are as 
follows and shown without derivation.</p>
<p><span class="math display">\[
\begin{aligned}
s=RSE=\sqrt{\frac{\sum{(y_i-(\beta_0+\beta_1x_i))^2}}{n-2}  } =\sqrt{\frac{\sum{\epsilon^2}}{n-2}  } \\
SE(\hat{\beta_1})=\frac{s}{\sqrt{\sum{(x_i-\overline{X})^2}}} \\
SE(\hat{\beta_0})=s\sqrt{ \frac{1}{n} + \frac{\overline{X}^2}{\sum{(x_i-\overline{X})^2} }  }
\end{aligned}
\]</span></p>
<p>Notice that that <span class="math inline">\(SE(\beta_1)\)</span> depends on the estimate of variance of
residuals shown as <span class="math inline">\(s\)</span> or <strong>Residual Standard Error (RSE)</strong>. 
Notice also the standard error depends on the spread of <span class="math inline">\(X\)</span>. If <span class="math inline">\(X\)</span> values have more 
variation, the standard error will be lower. This intuitively makes sense since if the
spread of <span class="math inline">\(X\)</span> is low, the regression line will be able to wiggle more
compared to a regression line that is fit to the same number of points but
covers a greater range on the X-axis.</p>
<p>The standard error estimates can also be used to calculate confidence intervals and test
hypotheses, since the following quantity, called t-score, approximately follows a
t-distribution with <span class="math inline">\(n-p\)</span> degrees of freedom, where <span class="math inline">\(n\)</span> is the number
of data points and <span class="math inline">\(p\)</span> is the number of coefficients estimated.</p>
<p><span class="math display">\[ \frac{\hat{\beta_i}-\beta_test}{SE(\hat{\beta_i})}\]</span></p>
<p>Often, we would like to test the null hypothesis if a coefficient is equal to
zero or not. For simple regression, this could mean if there is a relationship
between the explanatory variable and the response variable. We would calculate the
t-score as follows <span class="math inline">\(\frac{\hat{\beta_i}-0}{SE(\hat{\beta_i})}\)</span>, and compare it
to the t-distribution with <span class="math inline">\(d.f.=n-p\)</span> to get the p-value.</p>
<p>We can also
calculate the uncertainty of the regression coefficients using confidence
intervals, the range of values that are likely to contain <span class="math inline">\(\beta_i\)</span>. The 95%
confidence interval for <span class="math inline">\(\hat{\beta_i}\)</span> is
<span class="math inline">\(\hat{\beta_i}\)</span> ± <span class="math inline">\(t_{0.975}SE(\hat{\beta_i})\)</span>.
<span class="math inline">\(t_{0.975}\)</span> is the 97.5% percentile of
the t-distribution with <span class="math inline">\(d.f. = n – p\)</span>.</p>
<p>In R, the <code>summary()</code> function will test all the coefficients for the null hypothesis
<span class="math inline">\(\beta_i=0\)</span>. The function takes the model output obtained from the <code>lm()</code>
function. To demonstrate this, let us first get some data. The procedure below
simulates data to be used in a regression setting and it is useful to examine 
what the linear model expects to model the data.</p>
<p>Since we have the data, we can build our model and call the <code>summary</code> function.
We will then use the <code>confint()</code> function to get the confidence intervals on the
coefficients and the <code>coef()</code> function to pull out the estimated coefficients from
the model.</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="relationship-between-variables-linear-models-and-correlation.html#cb174-1"></a>mod1=<span class="kw">lm</span>(y<span class="op">~</span>x)</span>
<span id="cb174-2"><a href="relationship-between-variables-linear-models-and-correlation.html#cb174-2"></a><span class="kw">summary</span>(mod1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -77.11 -18.44   0.33  16.06  57.23 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.24538    6.28869   2.106   0.0377 *  
## x            0.49954    0.05131   9.736 4.54e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 28.77 on 98 degrees of freedom
## Multiple R-squared:  0.4917, Adjusted R-squared:  0.4865 
## F-statistic: 94.78 on 1 and 98 DF,  p-value: 4.537e-16</code></pre>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="relationship-between-variables-linear-models-and-correlation.html#cb176-1"></a><span class="co"># get confidence intervals </span></span>
<span id="cb176-2"><a href="relationship-between-variables-linear-models-and-correlation.html#cb176-2"></a><span class="kw">confint</span>(mod1)</span></code></pre></div>
<pre><code>##                 2.5 %     97.5 %
## (Intercept) 0.7656777 25.7250883
## x           0.3977129  0.6013594</code></pre>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="relationship-between-variables-linear-models-and-correlation.html#cb178-1"></a><span class="co"># pull out coefficients from the model</span></span>
<span id="cb178-2"><a href="relationship-between-variables-linear-models-and-correlation.html#cb178-2"></a><span class="kw">coef</span>(mod1)</span></code></pre></div>
<pre><code>## (Intercept)           x 
##  13.2453830   0.4995361</code></pre>
<p>The <code>summary()</code> function prints out an extensive list of values.
The “Coefficients” section has the estimates, their standard error, t score,
and the p-value from the hypothesis test <span class="math inline">\(H_0:\beta_i=0\)</span>. As you can see, the
estimate we get for the coefficients and their standard errors are close to
the ones we get from repeatedly sampling and getting a distribution of
coefficients. This is statistical inference at work, we can estimate the
population properties within a certain error using just a sample.</p>
</div>
<div id="accuracy-of-the-model" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Accuracy of the model</h3>
<p>If you have observed the table output of the <code>summary()</code> function, you must have noticed there are some other outputs, such as “Residual standard error”,
“Multiple R-squared” and “F-statistic”. These are metrics that are useful
for assessing the accuracy of the model. We will explain them one by one.</p>
<p><strong>RSE</strong> is simply the square-root of
the sum of squared error terms, divided by degrees of freedom, <span class="math inline">\(n-p\)</span>. For the simple
linear regression case, degrees of freedom is <span class="math inline">\(n-2\)</span>. Sum of the squares of the error terms is also
called the <strong>“Residual sum of squares”</strong>, RSS. So the RSE is
calculated as follows:</p>
<p><span class="math display">\[ s=RSE=\sqrt{\frac{\sum{(y_i-\hat{Y_i})^2 }}{n-p}}=\sqrt{\frac{RSS}{n-p}}\]</span></p>
<p>The RSE is a way of assessing the model fit. The larger the RSE the worse the
model is. However, this is an absolute measure in the units of <span class="math inline">\(Y\)</span> and we have nothing to
compare against. One idea is that we divide it by the RSS of a simpler model
for comparative purposes. That simpler model is in this case is the model
with the intercept, <span class="math inline">\(\beta_0\)</span>. A very bad model will have close to zero
coefficients for explanatory variables, and the RSS of that model
will be close to the RSS of the model with only the intercept. In such
a model the intercept will be equal to <span class="math inline">\(\overline{Y}\)</span>. As it turns out, the RSS of the model with
just the intercept is called the <em>“Total Sum of Squares” or TSS</em>. A good model will have a low <span class="math inline">\(RSS/TSS\)</span>. The metric <span class="math inline">\(R^2\)</span> uses these quantities to calculate a score between 0 and 1, and the closer to 1, the better the model. Here is how
it is calculated:</p>
<p><span class="math display">\[R^2=1-\frac{RSS}{TSS}=\frac{TSS-RSS}{TSS}=1-\frac{RSS}{TSS}\]</span></p>
<p>The <span class="math inline">\(TSS-RSS\)</span> part of the formula often referred to as “explained variability” in
the model. The bottom part is for “total variability”. With this interpretation, the higher
the “explained variability”, the better the model. For simple linear regression
with one explanatory variable, the square root of <span class="math inline">\(R^2\)</span> is a quantity known
as the absolute value of the correlation coefficient, which can be calculated for any pair of variables, not only
the
response and the explanatory variables. <em>Correlation</em> is the general measure of 
linear
relationship between two variables. One
of the most popular flavors of correlation is the Pearson correlation coefficient. Formally, it is the
<em>covariance</em> of X and Y divided by multiplication of standard deviations of 
X and Y. In R, it can be calculated with the <code>cor()</code> function.</p>
<p><span class="math display">\[ 
r_{xy}=\frac{cov(X,Y)}{\sigma_x\sigma_y}
      =\frac{\sum\limits_{i=1}^n (x_i-\bar{x})(y_i-\bar{y})}
            {\sqrt{\sum\limits_{i=1}^n (x_i-\bar{x})^2 \sum\limits_{i=1}^n (y_i-\bar{y})^2}}
\]</span>
In the equation above, <span class="math inline">\(cov\)</span> is the covariance; this is again a measure of
how much two variables change together, like correlation. If two variables 
show similar behavior, they will usually have a positive covariance value. If they have opposite behavior, the covariance will have a negative value.
However, these values are boundless. A normalized way of looking at
covariance is to divide covariance by the multiplication of standard
errors of X and Y. This bounds the values to -1 and 1, and as mentioned
above, is called Pearson correlation coefficient. The values that change in a similar manner will have a positive coefficient, the values that change in 
an opposite manner will have a negative coefficient, and pairs that do not have
a linear relationship will have <span class="math inline">\(0\)</span> or near <span class="math inline">\(0\)</span> correlation. In
Figure <a href="relationship-between-variables-linear-models-and-correlation.html#fig:CorCovar">3.17</a>, we are showing <span class="math inline">\(R^2\)</span>, correlation
the coefficient, and covariance for different scatter plots.</p>
<div class="figure" style="text-align: center"><span id="fig:CorCovar"></span>
<img src="03-statsForGenomics_files/figure-html/CorCovar-1.png" alt="Correlation and covariance for different scatter plots." width="100%" />
<p class="caption">
FIGURE 3.17: Correlation and covariance for different scatter plots.
</p>
</div>
<p>For simple linear regression, correlation can be used to assess the model. However, this becomes useless as a measure of general accuracy
if there is more than one explanatory variable as in multiple linear regression. In that case, <span class="math inline">\(R^2\)</span> is a measure
of accuracy for the model. Interestingly, the square of the
correlation of predicted values
and original response variables (<span class="math inline">\((cor(Y,\hat{Y}))^2\)</span> ) equals <span class="math inline">\(R^2\)</span> for 
multiple linear regression.</p>
<p>The last accuracy measure, or the model fit in general we are going to explain is <em>F-statistic</em>. This is a quantity that depends on the RSS and TSS again. It can also answer one important question that other metrics cannot easily answer. That question is whether or not any of the explanatory
variables have predictive value or in other words if all the explanatory variables are zero. We can write the null hypothesis as follows:</p>
<p><span class="math display">\[H_0: \beta_1=\beta_2=\beta_3=...=\beta_p=0 \]</span></p>
<p>where the alternative is:</p>
<p><span class="math display">\[H_1: \text{at least one } \beta_i \neq 0 \]</span></p>
<p>Remember that <span class="math inline">\(TSS-RSS\)</span> is analogous to “explained variability” and the RSS is
analogous to “unexplained variability”. For the F-statistic, we divide explained variance by
unexplained variance. Explained variance is just the <span class="math inline">\(TSS-RSS\)</span> divided
by degrees of freedom, and unexplained variance is the RSE.
The ratio will follow the F-distribution
with two parameters, the degrees of freedom for the explained variance and
the degrees of freedom for the unexplained variance. The F-statistic for a linear model is calculated as follows.</p>
<p><span class="math display">\[F=\frac{(TSS-RSS)/(p-1)}{RSS/(n-p)}=\frac{(TSS-RSS)/(p-1)}{RSE} \sim F(p-1,n-p)\]</span></p>
<p>If the variances are the same, the ratio will be 1, and when <span class="math inline">\(H_0\)</span> is true, then
it can be shown that expected value of <span class="math inline">\((TSS-RSS)/(p-1)\)</span> will be <span class="math inline">\(\sigma^2\)</span>, which is estimated by the RSE. So, if the variances are significantly different,
the ratio will need to be significantly bigger than 1.
If the ratio is large enough we can reject the null hypothesis. To asses that
we need to use software or look up the tables for F statistics with calculated
parameters. In R, function <code>qf()</code> can be used to calculate critical value of the
ratio. Benefit of the F-test over
looking at significance of coefficients one by one is that we circumvent
multiple testing problem. If there are lots of explanatory variables
at least 5% of the time (assuming we use 0.05 as P-value significance
cutoff), p-values from coefficient t-tests will be wrong. In summary, F-test is a better choice for testing if there is any association
between the explanatory variables and the response variable.</p>
</div>
<div id="regression-with-categorical-variables" class="section level3">
<h3><span class="header-section-number">3.3.4</span> Regression with categorical variables</h3>
<p>An important feature of linear regression is that categorical variables can
be used as explanatory variables, this feature is very useful in genomics
where explanatory variables can often be categorical. To put it in
context, in our histone modification  example we can also include if
promoters have CpG islands or not as a variable. In addition, in
differential gene expression, we usually test the difference between
different conditions, which can be encoded as categorical variables in
a linear regression. We can sure use the t-test for that as well if there are only 2 conditions, but if there are more conditions and other variables
to control for, such as age or sex of the samples, we need to take those
into account for our statistics, and the t-test alone cannot handle such
complexity. In addition, when we have categorical variables we can also
have numeric variables in the model and we certainly do not have to include
only one type of variable in a model.</p>
<p>The simplest model with categorical variables includes two levels that
can be encoded in 0 and 1. Below, we show linear regression with categorical variables. We then plot the fitted line. This plot is shown in Figure <a href="relationship-between-variables-linear-models-and-correlation.html#fig:LMcategorical">3.18</a>.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="relationship-between-variables-linear-models-and-correlation.html#cb180-1"></a><span class="kw">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb180-2"><a href="relationship-between-variables-linear-models-and-correlation.html#cb180-2"></a>gene1=<span class="kw">rnorm</span>(<span class="dv">30</span>,<span class="dt">mean=</span><span class="dv">4</span>,<span class="dt">sd=</span><span class="dv">2</span>)</span>
<span id="cb180-3"><a href="relationship-between-variables-linear-models-and-correlation.html#cb180-3"></a>gene2=<span class="kw">rnorm</span>(<span class="dv">30</span>,<span class="dt">mean=</span><span class="dv">2</span>,<span class="dt">sd=</span><span class="dv">2</span>)</span>
<span id="cb180-4"><a href="relationship-between-variables-linear-models-and-correlation.html#cb180-4"></a>gene.df=<span class="kw">data.frame</span>(<span class="dt">exp=</span><span class="kw">c</span>(gene1,gene2),</span>
<span id="cb180-5"><a href="relationship-between-variables-linear-models-and-correlation.html#cb180-5"></a>                  <span class="dt">group=</span><span class="kw">c</span>( <span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">30</span>),<span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">30</span>) ) )</span>
<span id="cb180-6"><a href="relationship-between-variables-linear-models-and-correlation.html#cb180-6"></a></span>
<span id="cb180-7"><a href="relationship-between-variables-linear-models-and-correlation.html#cb180-7"></a>mod2=<span class="kw">lm</span>(exp<span class="op">~</span>group,<span class="dt">data=</span>gene.df)</span>
<span id="cb180-8"><a href="relationship-between-variables-linear-models-and-correlation.html#cb180-8"></a><span class="kw">summary</span>(mod2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = exp ~ group, data = gene.df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.7290 -1.0664  0.0122  1.3840  4.5629 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.1851     0.3517   6.214 6.04e-08 ***
## group         1.8726     0.4973   3.765 0.000391 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.926 on 58 degrees of freedom
## Multiple R-squared:  0.1964, Adjusted R-squared:  0.1826 
## F-statistic: 14.18 on 1 and 58 DF,  p-value: 0.0003905</code></pre>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="relationship-between-variables-linear-models-and-correlation.html#cb182-1"></a><span class="kw">require</span>(mosaic)</span>
<span id="cb182-2"><a href="relationship-between-variables-linear-models-and-correlation.html#cb182-2"></a><span class="kw">plotModel</span>(mod2)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:LMcategorical"></span>
<img src="03-statsForGenomics_files/figure-html/LMcategorical-1.png" alt="Linear model with a categorical variable coded as 0 and 1." width="50%" />
<p class="caption">
FIGURE 3.18: Linear model with a categorical variable coded as 0 and 1.
</p>
</div>
<p>We can even compare more levels,and we do not even have to encode them
ourselves. We can pass categorical variables to the <code>lm()</code> function.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="relationship-between-variables-linear-models-and-correlation.html#cb183-1"></a>gene.df=<span class="kw">data.frame</span>(<span class="dt">exp=</span><span class="kw">c</span>(gene1,gene2,gene2),</span>
<span id="cb183-2"><a href="relationship-between-variables-linear-models-and-correlation.html#cb183-2"></a>                  <span class="dt">group=</span><span class="kw">c</span>( <span class="kw">rep</span>(<span class="st">&quot;A&quot;</span>,<span class="dv">30</span>),<span class="kw">rep</span>(<span class="st">&quot;B&quot;</span>,<span class="dv">30</span>),<span class="kw">rep</span>(<span class="st">&quot;C&quot;</span>,<span class="dv">30</span>) ) </span>
<span id="cb183-3"><a href="relationship-between-variables-linear-models-and-correlation.html#cb183-3"></a>                  )</span>
<span id="cb183-4"><a href="relationship-between-variables-linear-models-and-correlation.html#cb183-4"></a></span>
<span id="cb183-5"><a href="relationship-between-variables-linear-models-and-correlation.html#cb183-5"></a>mod3=<span class="kw">lm</span>(exp<span class="op">~</span>group,<span class="dt">data=</span>gene.df)</span>
<span id="cb183-6"><a href="relationship-between-variables-linear-models-and-correlation.html#cb183-6"></a><span class="kw">summary</span>(mod3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = exp ~ group, data = gene.df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.7290 -1.0793 -0.0976  1.4844  4.5629 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   4.0577     0.3781  10.731  &lt; 2e-16 ***
## groupB       -1.8726     0.5348  -3.502 0.000732 ***
## groupC       -1.8726     0.5348  -3.502 0.000732 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.071 on 87 degrees of freedom
## Multiple R-squared:  0.1582, Adjusted R-squared:  0.1388 
## F-statistic: 8.174 on 2 and 87 DF,  p-value: 0.0005582</code></pre>
</div>
<div id="regression-pitfalls" class="section level3">
<h3><span class="header-section-number">3.3.5</span> Regression pitfalls</h3>
<p>In most cases one should look at the error terms (residuals) vs. the fitted
values plot. Any structure in this plot indicates problems such as
non-linearity, correlation of error terms, non-constant variance or
unusual values driving the fit. Below we briefly explain the potential
issues with the linear regression.</p>
<div id="non-linearity" class="section level5">
<h5><span class="header-section-number">3.3.5.0.1</span> Non-linearity</h5>
<p>If the true relationship is far from linearity, prediction accuracy
is reduced and all the other conclusions are questionable. In some cases,
transforming the data with <span class="math inline">\(logX\)</span>, <span class="math inline">\(\sqrt{X}\)</span>, and <span class="math inline">\(X^2\)</span> could resolve
the issue.</p>
</div>
<div id="correlation-of-explanatory-variables" class="section level5">
<h5><span class="header-section-number">3.3.5.0.2</span> Correlation of explanatory variables</h5>
<p>If the explanatory variables are correlated that could lead to something<br />
known as multicolinearity. When this happens SE estimates of the coefficients will be too large. This is usually observed in time-course
data.</p>
</div>
<div id="correlation-of-error-terms" class="section level5">
<h5><span class="header-section-number">3.3.5.0.3</span> Correlation of error terms</h5>
<p>This assumes that the errors of the response variables are uncorrelated with each other. If they are, the confidence intervals of the coefficients
might too narrow.</p>
</div>
<div id="non-constant-variance-of-error-terms" class="section level5">
<h5><span class="header-section-number">3.3.5.0.4</span> Non-constant variance of error terms</h5>
<p>This means that different response variables have the same variance in their errors, regardless of the values of the predictor variables. If
the errors are not constant (Ex: the errors grow as X values increase), this
will result in unreliable estimates in standard errors as the model
assumes constant variance. Transformation of data, such as
<span class="math inline">\(logX\)</span> and <span class="math inline">\(\sqrt{X}\)</span>, could help in some cases.</p>
</div>
<div id="outliers-and-high-leverage-points" class="section level5">
<h5><span class="header-section-number">3.3.5.0.5</span> Outliers and high leverage points</h5>
<p>Outliers are extreme values for Y and high leverage points are unusual
X values. Both of these extremes have the power to affect the fitted line
and the standard errors. In some cases (Ex: if there are measurement errors), they can be
removed from the data for a better fit.</p>

<div class="rmdtip">
<p><strong>Want to know more ?</strong></p>
<ul>
<li>Linear models and derivations of equations including matrix notation
<ul>
<li><em>Applied Linear Statistical Models</em> by Kutner, Nachtsheim, et al. <span class="citation">(Kutner, Nachtsheim, and Neter <a href="#ref-kutner2003applied" role="doc-biblioref">2003</a>)</span></li>
<li><em>Elements of Statistical Learning</em> by Hastie &amp; Tibshirani <span class="citation">(J. Friedman, Hastie, and Tibshirani <a href="#ref-friedman2001elements" role="doc-biblioref">2001</a>)</span></li>
<li><em>An Introduction to Statistical Learning</em> by James, Witten, et al. <span class="citation">(James, Witten, Hastie, et al. <a href="#ref-james2013introduction" role="doc-biblioref">2013</a>)</span></li>
</ul></li>
</ul>
</div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-friedman2001elements">
<p>Friedman, Hastie, and Tibshirani. 2001. <em>The Elements of Statistical Learning</em>. Vol. 1. Springer series in statistics New York.</p>
</div>
<div id="ref-james2013introduction">
<p>James, Witten, Hastie, and Tibshirani. 2013. <em>An Introduction to Statistical Learning: With Applications in R</em>. Springer Texts in Statistics. Springer New York. <a href="https://books.google.de/books?id=qcI\_AAAAQBAJ">https://books.google.de/books?id=qcI\_AAAAQBAJ</a>.</p>
</div>
<div id="ref-kutner2003applied">
<p>Kutner, Nachtsheim, and Neter. 2003. <em>Applied Linear Regression Models</em>. The Mcgraw-Hill/Irwin Series Operations and Decision Sciences. McGraw-Hill Higher Education. <a href="https://books.google.de/books?id=0nAMAAAACAAJ">https://books.google.de/books?id=0nAMAAAACAAJ</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="how-to-test-for-differences-between-samples.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exercises-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/compgenomr/book/edit/master/03-statsForGenomics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
